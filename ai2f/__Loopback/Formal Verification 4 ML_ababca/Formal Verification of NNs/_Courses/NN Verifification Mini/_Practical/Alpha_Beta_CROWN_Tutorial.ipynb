{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu6MUQmRUR_i"
      },
      "source": [
        "# $\\alpha,\\!\\beta$-CROWN Verifier Quick Start Tutorial\n",
        "$\\alpha,\\!\\beta$-CROWN (alpha-beta-CROWN) is a neural network verifier based on an efficient bound propagation algorithm (CROWN) and branch and bound. It can be accelerated efficiently on GPUs and can scale to relatively large convolutional networks. It also supports a wide range of neural network architectures (e.g., CNN, ResNet, and various activation functions), thanks to the versatile auto_LiRPA library developed by us. α,β-CROWN can provide provable robustness guarantees against adversarial attacks and can also verify other general properties of neural networks.\n",
        "\n",
        "α,β-CROWN is the winning verifier in VNN-COMP 2021 (International Verification of Neural Networks Competition) with the highest total score, outperforming 11 other neural network verifiers on a wide range of benchmarks. Code can be downloaded at [α,β-CROWN repo](https://github.com/huanzhang12/alpha-beta-CROWN) with detailed and friendly [instructions for usages](https://github.com/huanzhang12/alpha-beta-CROWN/tree/main/docs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjYhHLlxHI3K"
      },
      "source": [
        "## Installation & Imports\n",
        "We first install α,β-CROWN with given environment.yml. Note that our library is tested on Pytorch 1.8.2 LTS, and other versions might be incompatible."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install miniconda"
      ],
      "metadata": {
        "id": "xQs8jcIE6rdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "%env PYTHONPATH=\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "QbxHzCph6mvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "984ISxXg7KgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path\n",
        "!ls /usr/local/lib/python3.7/dist-packages\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ],
      "metadata": {
        "id": "pbxK8-HG8QlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clone the alpha-beta-crown repo"
      ],
      "metadata": {
        "id": "hQGkgRhgMTTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall existing Pytorch on Colab, which might be incompatible or buggy.\n",
        "# !pip uninstall --yes torch torchvision torchaudio torchtext\n",
        "!git clone https://github.com/huanzhang12/alpha-beta-CROWN.git"
      ],
      "metadata": {
        "id": "Hl6Kr7sI9p0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create conda environment according to provided environment.yml"
      ],
      "metadata": {
        "id": "ni910HoIMX4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Remove the old environment, if necessary.\n",
        "conda env remove --name alpha-beta-crown\n",
        "conda env create -f alpha-beta-CROWN/complete_verifier/environment.yml  # install all dependents into the alpha-beta-crown environment\n",
        "# conda activate alpha-beta-crown  # activate the environment"
      ],
      "metadata": {
        "id": "g5xgqfEw73L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQJWL04XK0Fx"
      },
      "source": [
        "Go to the running folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd alpha-beta-CROWN/complete_verifier/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0toepwVIFTG",
        "outputId": "df08ae80-843e-4721-b172-7d62235064f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpha-beta-CROWN/complete_verifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial example1: Running MNIST example\n",
        "Here we define our own config file. Forr instance, we define a testing example for mnist_cnn_a_adv model with epsilon 0.3"
      ],
      "metadata": {
        "id": "adM-HNJEMdXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a exp_configs/tutorial_mnist_example.yaml\n",
        "general:\n",
        "  mode: verified-acc\n",
        "model:\n",
        "  name: mnist_cnn_4layer\n",
        "  path: models/sdp/mnist_cnn_a_adv.model\n",
        "data:\n",
        "  dataset: MNIST\n",
        "  std: [1.]\n",
        "  mean: [0.]\n",
        "specification:\n",
        "  epsilon: 0.3\n",
        "attack:\n",
        "  pgd_restarts: 50\n",
        "solver:\n",
        "  beta-crown:\n",
        "    batch_size: 1024\n",
        "    iteration: 20\n",
        "bab:\n",
        "  timeout: 180"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euo2qbutIK03",
        "outputId": "d25284d1-c3b5-485c-c938-4779e340a98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing exp_configs/tutorial_mnist_example.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "activate the conda environment and run the verification on mnist sample index 21"
      ],
      "metadata": {
        "id": "VAdJ6KNsMrjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate alpha-beta-crown\n",
        "# python robustness_verifier.py --config exp_configs/tutorial_mnist_example.yaml --start 0 --end 1\n",
        "# python robustness_verifier.py --config exp_configs/tutorial_mnist_example.yaml --start 1 --end 2\n",
        "python robustness_verifier.py --config exp_configs/tutorial_mnist_example.yaml --start 21 --end 22\n",
        "conda deactivate"
      ],
      "metadata": {
        "id": "qxLqjQxzF6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559e1149-42ce-48c2-f927-62ad9b8e5f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cuda\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/sdp/mnist_cnn_a_adv.model\n",
            "  name: mnist_cnn_4layer\n",
            "data:\n",
            "  start: 21\n",
            "  end: 22\n",
            "  num_outputs: 10\n",
            "  mean: [0.0]\n",
            "  std: [1.0]\n",
            "  pkl_path: null\n",
            "  dataset: MNIST\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 0.3\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 100\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 1024\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 20\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 200000\n",
            "  decision_thresh: 0\n",
            "  timeout: 180\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 50\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Wed Feb 23 07:35:53 2022 on 19a7eca73961\n",
            "Sequential(\n",
            "  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  (3): ReLU()\n",
            "  (4): Flatten()\n",
            "  (5): Linear(in_features=1568, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "Trying generic MNIST/CIFAR data loader.\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/train-images-idx3-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/train-labels-idx1-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Extracting /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "Done!\n",
            "epsilon after preprocessing: tensor([[[[0.3000]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])\n",
            "Task length: 1\n",
            "saving results to Verified_ret_[mnist_cnn_4layer]_start=21_end=22_iter=20_b=1024_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 21 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 6, correct label 6, image norm 87.4627456665039, logits tensor([-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "        -1.6112, -4.8054], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 6, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-7.1670, -5.6796, -3.0066, -1.8039, -3.4453,  0.8696,  4.0714, -8.4145,\n",
            "        -0.7747, -4.7484], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([11.2383,  9.7509,  7.0780,  5.8752,  7.5166,  3.2017,     inf, 12.4858,\n",
            "         4.8461,  8.8197], device='cuda:0', grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "         -1.6112, -4.8054]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[-2.8491, -5.1546, -6.1212, -6.5010, -4.7507, -6.9077, -4.2327, -4.9323,\n",
            "         -4.2137]], device='cuda:0') None\n",
            "best_l after optimization: 3.280125379562378 with beta sum per layer: []\n",
            "alpha/beta optimization time: 4.545588493347168\n",
            "initial alpha-CROWN bounds: tensor([[ 1.4412,  0.7454, -1.4381, -2.0807, -0.3068, -2.3885,  1.1392, -0.7440,\n",
            "          0.3523]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "Sorted order for labels to attack: [5, 8, 3, 2, 4, 9, 1, 0, 7, 6]\n",
            "##### [0:21] Tested against 5 ######\n",
            "Model prediction is: tensor([[-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "         -1.6112, -4.8054]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /10 start_node /11\n",
            "setting alpha for layer /10 start_node /21\n",
            "not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))\n",
            "setting alpha for layer /12 start_node /21\n",
            "not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))\n",
            "not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))\n",
            "0 /9 torch.Size([1, 16, 14, 14])\n",
            "1 /11 torch.Size([1, 32, 7, 7])\n",
            "2 /21 torch.Size([1, 100])\n",
            "best_l after optimization: 2.3832995891571045 with beta sum per layer: []\n",
            "alpha/beta optimization time: 1.1771368980407715\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-2.3833]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-2.3832995891571045\n",
            "layer 0 size torch.Size([3136]) unstable 1258\n",
            "layer 1 size torch.Size([1568]) unstable 193\n",
            "layer 2 size torch.Size([100]) unstable 20\n",
            "-----------------\n",
            "# of unstable neurons: 1471\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[2, 63]]\n",
            "best_l after optimization: 2.947624444961548 with beta sum per layer: [0.0, 0.0, 0.06192025542259216]\n",
            "alpha/beta optimization time: 0.5543127059936523\n",
            "This batch time : update_bounds func: 0.5591\t prepare: 0.0039\t bound: 0.5545\t transfer: 0.0004\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 0.5591\t prepare: 0.0039\t bound: 0.5545\t transfer: 0.0004\t finalize: 0.0003\n",
            "batch bounding time:  0.5592503547668457\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-1.96507, 96.616699] (1), [-0.98256, 96.616699] (1), \n",
            "length of domains: 2\n",
            "Total time: 0.5863\t pickout: 0.0072\t decision: 0.0197\t get_bound: 0.5593\t add_domain: 0.0001\n",
            "Current lb:-1.96506929397583\n",
            "2 neurons visited\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 2.1594884395599365\n",
            "\n",
            "splitting decisions: [[1, 275], [2, 78]]\n",
            "best_l after optimization: 4.029561996459961 with beta sum per layer: [0.0, 0.06099735200405121, 0.16722486913204193]\n",
            "alpha/beta optimization time: 0.216996431350708\n",
            "This batch time : update_bounds func: 0.2194\t prepare: 0.0015\t bound: 0.2172\t transfer: 0.0005\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 0.7786\t prepare: 0.0053\t bound: 0.7717\t transfer: 0.0005\t finalize: 0.0006\n",
            "batch bounding time:  0.21953678131103516\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-1.50592, 96.616699] (2), [-1.35222, 96.616699] (2), [-0.64787, 96.616699] (2), [-0.52354, 96.616699] (2), \n",
            "length of domains: 4\n",
            "Total time: 0.2366\t pickout: 0.0008\t decision: 0.0160\t get_bound: 0.2195\t add_domain: 0.0002\n",
            "Current lb:-1.5059237480163574\n",
            "6 neurons visited\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 2.396146535873413\n",
            "\n",
            "splitting decisions: [[2, 81], [2, 81], [2, 81], [2, 81]]\n",
            "best_l after optimization: 1.4102717638015747 with beta sum per layer: [0.0, 0.09266588091850281, 1.232080101966858]\n",
            "alpha/beta optimization time: 0.19869756698608398\n",
            "This batch time : update_bounds func: 0.2017\t prepare: 0.0017\t bound: 0.1989\t transfer: 0.0006\t finalize: 0.0005\n",
            "Accumulated time: update_bounds func: 0.9803\t prepare: 0.0070\t bound: 0.9706\t transfer: 0.0006\t finalize: 0.0011\n",
            "batch bounding time:  0.2018420696258545\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-1.13347, 96.616699] (3), [-0.97479, 96.616699] (3), [-0.33778, 96.616699] (3), [-0.21569, 96.616699] (3), \n",
            "length of domains: 4\n",
            "Total time: 0.2200\t pickout: 0.0009\t decision: 0.0171\t get_bound: 0.2019\t add_domain: 0.0002\n",
            "Current lb:-1.1334729194641113\n",
            "14 neurons visited\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 2.616206645965576\n",
            "\n",
            "splitting decisions: [[1, 422], [1, 422], [1, 275], [1, 275]]\n",
            "best_l after optimization: 1.3195362091064453 with beta sum per layer: [0.0, 1.228232502937317, 0.24579684436321259]\n",
            "alpha/beta optimization time: 0.21133947372436523\n",
            "This batch time : update_bounds func: 0.2147\t prepare: 0.0018\t bound: 0.2116\t transfer: 0.0006\t finalize: 0.0007\n",
            "Accumulated time: update_bounds func: 1.1950\t prepare: 0.0088\t bound: 1.1821\t transfer: 0.0006\t finalize: 0.0018\n",
            "batch bounding time:  0.21479535102844238\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.73719, 96.616699] (4), [-0.58592, 96.616699] (4), [-0.08400, 96.616699] (4), [-0.06773, 96.616699] (4), [-0.00747, 96.616699] (4), \n",
            "length of domains: 5\n",
            "Total time: 0.2323\t pickout: 0.0009\t decision: 0.0164\t get_bound: 0.2148\t add_domain: 0.0002\n",
            "Current lb:-0.7371916770935059\n",
            "22 neurons visited\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 2.848665952682495\n",
            "\n",
            "splitting decisions: [[1, 1206], [1, 1206], [1, 912], [1, 1206], [1, 912]]\n",
            "best_l after optimization: -0.5695943832397461 with beta sum per layer: [0.0, 2.22294282913208, 0.12203076481819153]\n",
            "alpha/beta optimization time: 0.20205259323120117\n",
            "This batch time : update_bounds func: 0.2056\t prepare: 0.0020\t bound: 0.2023\t transfer: 0.0007\t finalize: 0.0007\n",
            "Accumulated time: update_bounds func: 1.4006\t prepare: 0.0107\t bound: 1.3844\t transfer: 0.0007\t finalize: 0.0025\n",
            "batch bounding time:  0.20572543144226074\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.38971, 96.616699] (5), [-0.27910, 96.616699] (5), [-0.13861, 96.616699] (5), [-0.02709, 96.616699] (5), \n",
            "length of domains: 4\n",
            "Total time: 0.2251\t pickout: 0.0012\t decision: 0.0179\t get_bound: 0.2057\t add_domain: 0.0002\n",
            "Current lb:-0.3897066116333008\n",
            "32 neurons visited\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 3.0738630294799805\n",
            "\n",
            "splitting decisions: [[2, 78], [2, 78], [1, 912], [2, 78]]\n",
            "best_l after optimization: -1.4588642120361328 with beta sum per layer: [0.0, 1.8133989572525024, 0.0]\n",
            "alpha/beta optimization time: 0.1930372714996338\n",
            "This batch time : update_bounds func: 0.1958\t prepare: 0.0016\t bound: 0.1932\t transfer: 0.0005\t finalize: 0.0004\n",
            "Accumulated time: update_bounds func: 1.5964\t prepare: 0.0123\t bound: 1.5776\t transfer: 0.0005\t finalize: 0.0029\n",
            "batch bounding time:  0.19588613510131836\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.05873, 96.616699] (6), \n",
            "length of domains: 1\n",
            "Total time: 0.2146\t pickout: 0.0009\t decision: 0.0176\t get_bound: 0.1959\t add_domain: 0.0001\n",
            "Current lb:-0.05873298645019531\n",
            "40 neurons visited\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 3.2886006832122803\n",
            "\n",
            "splitting decisions: [[1, 723]]\n",
            "\n",
            "all verified at 0th iter\n",
            "best_l after optimization: -0.5110645294189453 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.007630348205566406\n",
            "This batch time : update_bounds func: 0.0098\t prepare: 0.0014\t bound: 0.0078\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 1.6062\t prepare: 0.0137\t bound: 1.5854\t transfer: 0.0004\t finalize: 0.0031\n",
            "batch bounding time:  0.00983428955078125\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.0253\t pickout: 0.0006\t decision: 0.0148\t get_bound: 0.0098\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 96.61669921875, batch ub: inf\n",
            "Cumulative time: 3.3142542839050293\n",
            "\n",
            "Image 21 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound 96.61669921875, time: 3.3624014854431152\n",
            "21 1.0000000116860974e-07\n",
            "##### [0:21] Tested against 8 ######\n",
            "Model prediction is: tensor([[-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "         -1.6112, -4.8054]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /10 start_node /11\n",
            "setting alpha for layer /10 start_node /21\n",
            "not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))\n",
            "setting alpha for layer /12 start_node /21\n",
            "not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))\n",
            "not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))\n",
            "0 /9 torch.Size([1, 16, 14, 14])\n",
            "1 /11 torch.Size([1, 32, 7, 7])\n",
            "2 /21 torch.Size([1, 100])\n",
            "best_l after optimization: 0.7383358478546143 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.7681996822357178\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-0.7383]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-0.7383358478546143\n",
            "layer 0 size torch.Size([3136]) unstable 1258\n",
            "layer 1 size torch.Size([1568]) unstable 193\n",
            "layer 2 size torch.Size([100]) unstable 20\n",
            "-----------------\n",
            "# of unstable neurons: 1471\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[2, 63]]\n",
            "best_l after optimization: 0.16913318634033203 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.20206189155578613\n",
            "This batch time : update_bounds func: 0.2039\t prepare: 0.0011\t bound: 0.2022\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 1.8101\t prepare: 0.0148\t bound: 1.7876\t transfer: 0.0004\t finalize: 0.0033\n",
            "batch bounding time:  0.20404458045959473\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.23514, 98.261665] (1), \n",
            "length of domains: 1\n",
            "Total time: 0.2208\t pickout: 0.0006\t decision: 0.0161\t get_bound: 0.2041\t add_domain: 0.0001\n",
            "Current lb:-0.23514318466186523\n",
            "2 neurons visited\n",
            "Global ub: 98.26166534423828, batch ub: inf\n",
            "Cumulative time: 1.023120403289795\n",
            "\n",
            "splitting decisions: [[2, 14]]\n",
            "\n",
            "all verified at 0th iter\n",
            "best_l after optimization: -0.7552824020385742 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.006722211837768555\n",
            "This batch time : update_bounds func: 0.0085\t prepare: 0.0011\t bound: 0.0069\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 1.8187\t prepare: 0.0159\t bound: 1.7945\t transfer: 0.0004\t finalize: 0.0035\n",
            "batch bounding time:  0.008565187454223633\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.0248\t pickout: 0.0006\t decision: 0.0156\t get_bound: 0.0086\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 98.26166534423828, batch ub: inf\n",
            "Cumulative time: 1.0479552745819092\n",
            "\n",
            "Image 21 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound 98.26166534423828, time: 1.0963380336761475\n",
            "21 1.0000000116860974e-07\n",
            "##### [0:21] Tested against 3 ######\n",
            "Model prediction is: tensor([[-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "         -1.6112, -4.8054]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /10 start_node /11\n",
            "setting alpha for layer /10 start_node /21\n",
            "not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))\n",
            "setting alpha for layer /12 start_node /21\n",
            "not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))\n",
            "not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))\n",
            "0 /9 torch.Size([1, 16, 14, 14])\n",
            "1 /11 torch.Size([1, 32, 7, 7])\n",
            "2 /21 torch.Size([1, 100])\n",
            "best_l after optimization: 2.0759153366088867 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.7576255798339844\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-2.0759]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-2.0759153366088867\n",
            "layer 0 size torch.Size([3136]) unstable 1258\n",
            "layer 1 size torch.Size([1568]) unstable 193\n",
            "layer 2 size torch.Size([100]) unstable 20\n",
            "-----------------\n",
            "# of unstable neurons: 1471\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[2, 63]]\n",
            "best_l after optimization: 2.239816188812256 with beta sum per layer: [0.0, 0.0, 0.07067742198705673]\n",
            "alpha/beta optimization time: 0.19828343391418457\n",
            "This batch time : update_bounds func: 0.2003\t prepare: 0.0012\t bound: 0.1985\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 2.0190\t prepare: 0.0171\t bound: 1.9930\t transfer: 0.0004\t finalize: 0.0037\n",
            "batch bounding time:  0.20042777061462402\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-1.51869, 96.924088] (1), [-0.72113, 96.924088] (1), \n",
            "length of domains: 2\n",
            "Total time: 0.2175\t pickout: 0.0006\t decision: 0.0164\t get_bound: 0.2004\t add_domain: 0.0001\n",
            "Current lb:-1.5186872482299805\n",
            "2 neurons visited\n",
            "Global ub: 96.92408752441406, batch ub: inf\n",
            "Cumulative time: 1.0093498229980469\n",
            "\n",
            "splitting decisions: [[2, 78], [2, 78]]\n",
            "best_l after optimization: 1.8836050033569336 with beta sum per layer: [0.0, 0.0, 0.14541783928871155]\n",
            "alpha/beta optimization time: 0.19125628471374512\n",
            "This batch time : update_bounds func: 0.1934\t prepare: 0.0013\t bound: 0.1914\t transfer: 0.0004\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 2.2125\t prepare: 0.0183\t bound: 2.1844\t transfer: 0.0004\t finalize: 0.0040\n",
            "batch bounding time:  0.19353485107421875\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.96668, 96.924088] (2), [-0.69435, 96.924088] (2), [-0.22274, 96.924088] (2), \n",
            "length of domains: 3\n",
            "Total time: 0.2108\t pickout: 0.0007\t decision: 0.0164\t get_bound: 0.1935\t add_domain: 0.0001\n",
            "Current lb:-0.9666805267333984\n",
            "6 neurons visited\n",
            "Global ub: 96.92408752441406, batch ub: inf\n",
            "Cumulative time: 1.2202212810516357\n",
            "\n",
            "splitting decisions: [[1, 275], [1, 275], [1, 408]]\n",
            "best_l after optimization: 0.7325439453125 with beta sum per layer: [0.0, 0.13425704836845398, 0.295958936214447]\n",
            "alpha/beta optimization time: 0.19807696342468262\n",
            "This batch time : update_bounds func: 0.2006\t prepare: 0.0014\t bound: 0.1982\t transfer: 0.0005\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 2.4130\t prepare: 0.0197\t bound: 2.3826\t transfer: 0.0005\t finalize: 0.0043\n",
            "batch bounding time:  0.20064210891723633\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.47290, 96.924088] (3), [-0.25829, 96.924088] (3), [-0.13442, 96.924088] (3), \n",
            "length of domains: 3\n",
            "Total time: 0.2178\t pickout: 0.0008\t decision: 0.0162\t get_bound: 0.2007\t add_domain: 0.0002\n",
            "Current lb:-0.4729042053222656\n",
            "12 neurons visited\n",
            "Global ub: 96.92408752441406, batch ub: inf\n",
            "Cumulative time: 1.4381158351898193\n",
            "\n",
            "splitting decisions: [[1, 422], [1, 422], [1, 422]]\n",
            "best_l after optimization: -2.1922497749328613 with beta sum per layer: [0.0, 0.26851409673690796, 0.16795271635055542]\n",
            "alpha/beta optimization time: 0.1891164779663086\n",
            "This batch time : update_bounds func: 0.1918\t prepare: 0.0015\t bound: 0.1893\t transfer: 0.0005\t finalize: 0.0005\n",
            "Accumulated time: update_bounds func: 2.6049\t prepare: 0.0212\t bound: 2.5719\t transfer: 0.0005\t finalize: 0.0048\n",
            "batch bounding time:  0.1919236183166504\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.03581, 96.924088] (4), \n",
            "length of domains: 1\n",
            "Total time: 0.2086\t pickout: 0.0008\t decision: 0.0156\t get_bound: 0.1920\t add_domain: 0.0001\n",
            "Current lb:-0.035808563232421875\n",
            "18 neurons visited\n",
            "Global ub: 96.92408752441406, batch ub: inf\n",
            "Cumulative time: 1.6467745304107666\n",
            "\n",
            "splitting decisions: [[1, 912]]\n",
            "\n",
            "all verified at 0th iter\n",
            "best_l after optimization: -0.8279457092285156 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.006759166717529297\n",
            "This batch time : update_bounds func: 0.0087\t prepare: 0.0011\t bound: 0.0069\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 2.6135\t prepare: 0.0224\t bound: 2.5788\t transfer: 0.0004\t finalize: 0.0050\n",
            "batch bounding time:  0.008702516555786133\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.0244\t pickout: 0.0006\t decision: 0.0151\t get_bound: 0.0087\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 96.92408752441406, batch ub: inf\n",
            "Cumulative time: 1.6713488101959229\n",
            "\n",
            "Image 21 label 3 verification end, final lower bound 1.0000000116860974e-07, upper bound 96.92408752441406, time: 1.7192776203155518\n",
            "21 1.0000000116860974e-07\n",
            "##### [0:21] Tested against 2 ######\n",
            "Model prediction is: tensor([[-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "         -1.6112, -4.8054]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /10 start_node /11\n",
            "setting alpha for layer /10 start_node /21\n",
            "not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))\n",
            "setting alpha for layer /12 start_node /21\n",
            "not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))\n",
            "not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))\n",
            "0 /9 torch.Size([1, 16, 14, 14])\n",
            "1 /11 torch.Size([1, 32, 7, 7])\n",
            "2 /21 torch.Size([1, 100])\n",
            "best_l after optimization: 1.434443473815918 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.7783200740814209\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-1.4344]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-1.434443473815918\n",
            "layer 0 size torch.Size([3136]) unstable 1258\n",
            "layer 1 size torch.Size([1568]) unstable 193\n",
            "layer 2 size torch.Size([100]) unstable 20\n",
            "-----------------\n",
            "# of unstable neurons: 1471\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[2, 63]]\n",
            "best_l after optimization: 1.1526589393615723 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.195068359375\n",
            "This batch time : update_bounds func: 0.1970\t prepare: 0.0011\t bound: 0.1952\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 2.8105\t prepare: 0.0235\t bound: 2.7741\t transfer: 0.0004\t finalize: 0.0052\n",
            "batch bounding time:  0.19707322120666504\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.71972, 97.565559] (1), [-0.43294, 97.565559] (1), \n",
            "length of domains: 2\n",
            "Total time: 0.2131\t pickout: 0.0006\t decision: 0.0153\t get_bound: 0.1971\t add_domain: 0.0001\n",
            "Current lb:-0.7197170257568359\n",
            "2 neurons visited\n",
            "Global ub: 97.56555938720703, batch ub: inf\n",
            "Cumulative time: 1.0272526741027832\n",
            "\n",
            "splitting decisions: [[2, 11], [1, 709]]\n",
            "best_l after optimization: 0.10392570495605469 with beta sum per layer: [0.0, 0.0, 0.2100917100906372]\n",
            "alpha/beta optimization time: 0.20704054832458496\n",
            "This batch time : update_bounds func: 0.2094\t prepare: 0.0014\t bound: 0.2072\t transfer: 0.0004\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 3.0199\t prepare: 0.0249\t bound: 2.9813\t transfer: 0.0004\t finalize: 0.0055\n",
            "batch bounding time:  0.20949816703796387\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.32178, 97.565559] (2), [-0.00362, 97.565559] (2), \n",
            "length of domains: 2\n",
            "Total time: 0.2279\t pickout: 0.0007\t decision: 0.0176\t get_bound: 0.2095\t add_domain: 0.0001\n",
            "Current lb:-0.3217782974243164\n",
            "6 neurons visited\n",
            "Global ub: 97.56555938720703, batch ub: inf\n",
            "Cumulative time: 1.255251169204712\n",
            "\n",
            "splitting decisions: [[2, 22], [2, 11]]\n",
            "\n",
            "all verified at 8th iter\n",
            "best_l after optimization: -1.0829296112060547 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.0848386287689209\n",
            "This batch time : update_bounds func: 0.0870\t prepare: 0.0012\t bound: 0.0850\t transfer: 0.0004\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 3.1069\t prepare: 0.0261\t bound: 3.0663\t transfer: 0.0004\t finalize: 0.0057\n",
            "batch bounding time:  0.0870673656463623\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.1031\t pickout: 0.0007\t decision: 0.0153\t get_bound: 0.0871\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 97.56555938720703, batch ub: inf\n",
            "Cumulative time: 1.3584098815917969\n",
            "\n",
            "Image 21 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound 97.56555938720703, time: 1.4055850505828857\n",
            "21 1.0000000116860974e-07\n",
            "##### [0:21] Tested against 4 ######\n",
            "Model prediction is: tensor([[-5.2739, -6.6406, -3.7660, -4.0826, -2.6455, -0.5452,  5.9269, -9.0433,\n",
            "         -1.6112, -4.8054]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /10 start_node /11\n",
            "setting alpha for layer /10 start_node /21\n",
            "not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))\n",
            "setting alpha for layer /12 start_node /21\n",
            "not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))\n",
            "not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))\n",
            "0 /9 torch.Size([1, 16, 14, 14])\n",
            "1 /11 torch.Size([1, 32, 7, 7])\n",
            "2 /21 torch.Size([1, 100])\n",
            "best_l after optimization: 0.30324745178222656 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.7784919738769531\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-0.3032]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-0.30324745178222656\n",
            "layer 0 size torch.Size([3136]) unstable 1258\n",
            "layer 1 size torch.Size([1568]) unstable 193\n",
            "layer 2 size torch.Size([100]) unstable 20\n",
            "-----------------\n",
            "# of unstable neurons: 1471\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[2, 11]]\n",
            "\n",
            "all verified at 0th iter\n",
            "best_l after optimization: -0.6197707653045654 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.0074503421783447266\n",
            "This batch time : update_bounds func: 0.0094\t prepare: 0.0011\t bound: 0.0076\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 3.1163\t prepare: 0.0272\t bound: 3.0740\t transfer: 0.0004\t finalize: 0.0059\n",
            "batch bounding time:  0.009394645690917969\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.0260\t pickout: 0.0005\t decision: 0.0161\t get_bound: 0.0094\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 98.6967544555664, batch ub: inf\n",
            "Cumulative time: 0.8387391567230225\n",
            "\n",
            "Image 21 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound 98.6967544555664, time: 0.8857119083404541\n",
            "21 1.0000000116860974e-07\n",
            "##### [0:21] Tested against 9 ######\n",
            "Initial alpha-CROWN verified for label 9 with bound 0.35231781005859375\n",
            "Image 21 label 9 verification end, final lower bound 0.35231781005859375, upper bound inf, time: 0.000370025634765625\n",
            "21 0.35231781005859375\n",
            "##### [0:21] Tested against 1 ######\n",
            "Initial alpha-CROWN verified for label 1 with bound 0.745366096496582\n",
            "Image 21 label 1 verification end, final lower bound 0.745366096496582, upper bound inf, time: 0.0003590583801269531\n",
            "21 0.745366096496582\n",
            "##### [0:21] Tested against 0 ######\n",
            "Initial alpha-CROWN verified for label 0 with bound 1.4411907196044922\n",
            "Image 21 label 0 verification end, final lower bound 1.4411907196044922, upper bound inf, time: 0.0003311634063720703\n",
            "21 1.4411907196044922\n",
            "##### [0:21] Tested against 7 ######\n",
            "Initial alpha-CROWN verified for label 7 with bound 1.1391592025756836\n",
            "Image 21 label 7 verification end, final lower bound 1.1391592025756836, upper bound inf, time: 0.0003275871276855469\n",
            "21 1.1391592025756836\n",
            "##### [0:21] Tested against 6 ######\n",
            "groundtruth label, skip!\n",
            "Result: image 21 verification success (with branch and bound)!\n",
            "Wall time: 15.963846683502197\n",
            "\n",
            "number of correctly classified examples: 1\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 0): []\n",
            "verification success idx (total 1): [21]\n",
            "verification failure idx (total 0): []\n",
            "final verified acc: 100.0%[1]\n",
            "verifier is called on 1 examples.\n",
            "total verified: 1\n",
            "mean time [cnt:1] (excluding attack success): 13.749964475631714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/9912422 [00:00<?, ?it/s]\r9913344it [00:00, 136688599.28it/s]        \n",
            "\r  0%|          | 0/28881 [00:00<?, ?it/s]\r29696it [00:00, 99484066.76it/s]         \n",
            "\r  0%|          | 0/1648877 [00:00<?, ?it/s]\r1649664it [00:00, 68799764.48it/s]         \n",
            "\r  0%|          | 0/4542 [00:00<?, ?it/s]\r5120it [00:00, 34918433.30it/s]         \n",
            "/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oSAAEAkUv9a"
      },
      "source": [
        "### More examples\n",
        "\n",
        "We provide many examples of `α,β-CROWN` in our repository with detailed config files at [here](https://github.com/huanzhang12/alpha-beta-CROWN/tree/main/complete_verifier/exp_configs)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customization on your own model and data\n",
        "One can easily customize the usage of α,β-CROWN to other dataset and self-defined models"
      ],
      "metadata": {
        "id": "Ch-7T_-vIdnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tutorial example 2: Customization for official CIFAR dataset and self-defined models"
      ],
      "metadata": {
        "id": "ZVVzoaqtq4hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile your_model_data.py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import arguments\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def simple_conv_model(in_channel, out_dim):\n",
        "    \"\"\"Simple Convolutional model.\"\"\"\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, 16, 4, stride=2, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 4, stride=2, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32*6*6,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, out_dim)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def cifar10(eps, use_bounds=False):\n",
        "    \"\"\"Example dataloader. For MNIST and CIFAR you can actually use existing ones in utils.py.\"\"\"\n",
        "    assert eps is not None\n",
        "    database_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'datasets')\n",
        "    # You can access the mean and std stored in config file.\n",
        "    mean = torch.tensor(arguments.Config[\"data\"][\"mean\"])\n",
        "    std = torch.tensor(arguments.Config[\"data\"][\"std\"])\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "    test_data = datasets.CIFAR10(database_path, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
        "    # Load entire dataset.\n",
        "    testloader = torch.utils.data.DataLoader(test_data, batch_size=10000, shuffle=False, num_workers=4)\n",
        "    X, labels = next(iter(testloader))\n",
        "    if use_bounds:\n",
        "        # Option 1: for each example, we return its element-wise lower and upper bounds.\n",
        "        # If you use this option, set --spec_type (\"specifications\"->\"type\" in config) to 'bound'.\n",
        "        absolute_max = torch.reshape((1. - mean) / std, (1, -1, 1, 1))\n",
        "        absolute_min = torch.reshape((0. - mean) / std, (1, -1, 1, 1))\n",
        "        # Be careful with normalization.\n",
        "        new_eps = torch.reshape(eps / std, (1, -1, 1, 1))\n",
        "        data_max = torch.min(X + new_eps, absolute_max)\n",
        "        data_min = torch.max(X - new_eps, absolute_min)\n",
        "        # In this case, the epsilon does not matter here.\n",
        "        ret_eps = None\n",
        "    else:\n",
        "        # Option 2: return a single epsilon for all data examples, as well as clipping lower and upper bounds.\n",
        "        # Set data_max and data_min to be None if no clip. For CIFAR-10 we clip to [0,1].\n",
        "        data_max = torch.reshape((1. - mean) / std, (1, -1, 1, 1))\n",
        "        data_min = torch.reshape((0. - mean) / std, (1, -1, 1, 1))\n",
        "        if eps is None:\n",
        "            raise ValueError('You must specify an epsilon')\n",
        "        # Rescale epsilon.\n",
        "        ret_eps = torch.reshape(eps / std, (1, -1, 1, 1))\n",
        "    return X, labels, data_max, data_min, ret_eps\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcYtWMSPrcP-",
        "outputId": "08f1f2cb-d85c-4654-f810-951bab5d3d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing your_model_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the config file with customized model \"simple_conv\" and dataset \"cifar10\""
      ],
      "metadata": {
        "id": "fyX9G1ILrs5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/tutorial_cifar_example.yaml\n",
        "general:\n",
        "  mode: verified-acc\n",
        "model:\n",
        "  # Use the simple_conv_model() model in \"your_model_data.py\".\n",
        "  name: Customized(\"your_model_data\", \"simple_conv_model\", in_channel=3, out_dim=10)\n",
        "  path: models/eran/cifar_conv_small_pgd.pth\n",
        "data:\n",
        "  # Use the cifar10() loader in \"your_model_data.py\".\n",
        "  dataset: Customized(\"your_model_data\", \"cifar10\")\n",
        "  mean: [0.4914, 0.4822, 0.4465]\n",
        "  std: [0.2023, 0.1994, 0.201]\n",
        "specification:\n",
        "  epsilon: 0.00784313725  # 2./255.\n",
        "attack:\n",
        "  pgd_restarts: 100\n",
        "solver:\n",
        "  beta-crown:\n",
        "    batch_size: 2048\n",
        "    iteration: 20\n",
        "bab:\n",
        "  max_domains: 5000000\n",
        "  timeout: 300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z3ZU8oqrMuH",
        "outputId": "44f418fd-c578-4695-9037-a251ea29da58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing exp_configs/tutorial_cifar_example.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can just run the verification:"
      ],
      "metadata": {
        "id": "MCeiKZg-r5sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate alpha-beta-crown\n",
        "python robustness_verifier.py --config exp_configs/tutorial_cifar_example.yaml --start 3 --end 4\n",
        "conda deactivate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVHLGb20r4xd",
        "outputId": "a49fca4c-8bdb-4eb9-ae54-3602a07d913e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cuda\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/eran/cifar_conv_small_pgd.pth\n",
            "  name: 'Customized(\"your_model_data\", \"simple_conv_model\", in_channel=3, out_dim=10)'\n",
            "data:\n",
            "  start: 3\n",
            "  end: 4\n",
            "  num_outputs: 10\n",
            "  mean: [0.4914, 0.4822, 0.4465]\n",
            "  std: [0.2023, 0.1994, 0.201]\n",
            "  pkl_path: null\n",
            "  dataset: 'Customized(\"your_model_data\", \"cifar10\")'\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 0.00784313725\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 100\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 2048\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 20\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 5000000\n",
            "  decision_thresh: 0\n",
            "  timeout: 300\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 100\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Wed Feb 23 07:36:36 2022 on 19a7eca73961\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (3): ReLU()\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1152, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/cifar-10-python.tar.gz\n",
            "Extracting /content/alpha-beta-CROWN/complete_verifier/datasets/cifar-10-python.tar.gz to /content/alpha-beta-CROWN/complete_verifier/datasets\n",
            "epsilon after preprocessing: tensor([[[[0.0388]],\n",
            "\n",
            "         [[0.0393]],\n",
            "\n",
            "         [[0.0390]]]]), data_max = tensor([[[[2.5141]],\n",
            "\n",
            "         [[2.5968]],\n",
            "\n",
            "         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],\n",
            "\n",
            "         [[-2.4183]],\n",
            "\n",
            "         [[-2.2214]]]])\n",
            "Task length: 1\n",
            "saving results to Verified_ret_[Customized(\"your_model_data\", \"simple_conv_model\", in_channel=3, out_dim=10)]_start=3_end=4_iter=20_b=2048_timeout=300_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 0, correct label 0, image norm 3647.6181640625, logits tensor([ 7.4902,  2.1212,  4.4477, -1.3335,  1.0948, -8.1737, -3.0771, -3.2288,\n",
            "         6.2792, -3.4130], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 0, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([ 7.0159,  1.9949,  4.4225, -1.1336,  0.9603, -8.0400, -2.9758, -3.2850,\n",
            "         6.7359, -3.4911], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([    inf,  5.0210,  2.5933,  8.1495,  6.0556, 15.0559,  9.9917, 10.3009,\n",
            "         0.2800, 10.5070], device='cuda:0', grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[ 7.4902,  2.1212,  4.4477, -1.3335,  1.0948, -8.1737, -3.0771, -3.2288,\n",
            "          6.2792, -3.4130]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[ 3.2842,  1.4734,  6.7423,  4.3338, 12.9471,  8.5598,  8.2946, -0.5469,\n",
            "          8.5043]], device='cuda:0') None\n",
            "best_l after optimization: -54.13715362548828 with beta sum per layer: []\n",
            "alpha/beta optimization time: 4.671474933624268\n",
            "initial alpha-CROWN bounds: tensor([[ 3.3625,  1.4996,  6.7996,  4.3903, 13.0312,  8.6178,  8.3613, -0.4932,\n",
            "          8.5679]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "Sorted order for labels to attack: [8, 2, 1, 4, 3, 6, 7, 9, 5, 0]\n",
            "##### [0:3] Tested against 8 ######\n",
            "Model prediction is: tensor([[ 7.4902,  2.1212,  4.4477, -1.3335,  1.0948, -8.1737, -3.0771, -3.2288,\n",
            "          6.2792, -3.4130]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /10 start_node /11\n",
            "setting alpha for layer /10 start_node /14\n",
            "not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))\n",
            "setting alpha for layer /12 start_node /14\n",
            "not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))\n",
            "not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))\n",
            "0 /9 torch.Size([1, 16, 15, 15])\n",
            "1 /11 torch.Size([1, 32, 6, 6])\n",
            "2 /14 torch.Size([1, 100])\n",
            "best_l after optimization: 0.49314379692077637 with beta sum per layer: []\n",
            "alpha/beta optimization time: 1.1963601112365723\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-0.4931]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-0.49314379692077637\n",
            "layer 0 size torch.Size([3600]) unstable 388\n",
            "layer 1 size torch.Size([1152]) unstable 114\n",
            "layer 2 size torch.Size([100]) unstable 21\n",
            "-----------------\n",
            "# of unstable neurons: 523\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[2, 26]]\n",
            "best_l after optimization: 0.6809237003326416 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.5752615928649902\n",
            "This batch time : update_bounds func: 0.5780\t prepare: 0.0019\t bound: 0.5755\t transfer: 0.0004\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 0.5780\t prepare: 0.0019\t bound: 0.5755\t transfer: 0.0004\t finalize: 0.0002\n",
            "batch bounding time:  0.5781447887420654\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.36509, 98.506859] (1), [-0.31583, 98.506859] (1), \n",
            "length of domains: 2\n",
            "Total time: 0.5972\t pickout: 0.0007\t decision: 0.0182\t get_bound: 0.5782\t add_domain: 0.0001\n",
            "Current lb:-0.3650939464569092\n",
            "2 neurons visited\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 2.165668487548828\n",
            "\n",
            "splitting decisions: [[2, 28], [2, 28]]\n",
            "best_l after optimization: 1.005408763885498 with beta sum per layer: [0.0, 0.0, 0.0]\n",
            "alpha/beta optimization time: 0.18510746955871582\n",
            "This batch time : update_bounds func: 0.1872\t prepare: 0.0012\t bound: 0.1853\t transfer: 0.0005\t finalize: 0.0003\n",
            "Accumulated time: update_bounds func: 0.7652\t prepare: 0.0031\t bound: 0.7607\t transfer: 0.0005\t finalize: 0.0005\n",
            "batch bounding time:  0.187286376953125\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.28019, 98.506859] (2), [-0.27426, 98.506859] (2), [-0.22808, 98.506859] (2), [-0.22287, 98.506859] (2), \n",
            "length of domains: 4\n",
            "Total time: 0.2035\t pickout: 0.0007\t decision: 0.0154\t get_bound: 0.1873\t add_domain: 0.0002\n",
            "Current lb:-0.2801942825317383\n",
            "6 neurons visited\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 2.369251012802124\n",
            "\n",
            "splitting decisions: [[2, 50], [2, 50], [2, 50], [2, 50]]\n",
            "best_l after optimization: 0.9810421466827393 with beta sum per layer: [0.0, 0.0, 1.3318638801574707]\n",
            "alpha/beta optimization time: 0.1880512237548828\n",
            "This batch time : update_bounds func: 0.1907\t prepare: 0.0014\t bound: 0.1882\t transfer: 0.0006\t finalize: 0.0004\n",
            "Accumulated time: update_bounds func: 0.9559\t prepare: 0.0045\t bound: 0.9490\t transfer: 0.0006\t finalize: 0.0009\n",
            "batch bounding time:  0.19076228141784668\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.21037, 98.506859] (3), [-0.20184, 98.506859] (3), [-0.15310, 98.506859] (3), [-0.14590, 98.506859] (3), [-0.09170, 98.506859] (3), [-0.09077, 98.506859] (3), [-0.04732, 98.506859] (3), [-0.04004, 98.506859] (3), \n",
            "length of domains: 8\n",
            "Total time: 0.2074\t pickout: 0.0009\t decision: 0.0154\t get_bound: 0.1908\t add_domain: 0.0003\n",
            "Current lb:-0.21036744117736816\n",
            "14 neurons visited\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 2.5767149925231934\n",
            "\n",
            "splitting decisions: [[2, 77], [2, 77], [2, 77], [2, 77], [2, 77], [2, 77], [2, 77], [2, 77]]\n",
            "best_l after optimization: 0.666262149810791 with beta sum per layer: [0.0, 0.0, 2.8375234603881836]\n",
            "alpha/beta optimization time: 0.202728271484375\n",
            "This batch time : update_bounds func: 0.2077\t prepare: 0.0030\t bound: 0.2030\t transfer: 0.0009\t finalize: 0.0008\n",
            "Accumulated time: update_bounds func: 1.1636\t prepare: 0.0074\t bound: 1.1520\t transfer: 0.0009\t finalize: 0.0017\n",
            "batch bounding time:  0.20783305168151855\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.14131, 98.506859] (4), [-0.13638, 98.506859] (4), [-0.11922, 98.506859] (4), [-0.10515, 98.506859] (4), [-0.08371, 98.506859] (4), [-0.07989, 98.506859] (4), [-0.06126, 98.506859] (4), [-0.04991, 98.506859] (4), [-0.02515, 98.506859] (4), [-0.02117, 98.506859] (4), \n",
            "length of domains: 10\n",
            "Total time: 0.2331\t pickout: 0.0012\t decision: 0.0235\t get_bound: 0.2079\t add_domain: 0.0004\n",
            "Current lb:-0.14131426811218262\n",
            "30 neurons visited\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 2.8099489212036133\n",
            "\n",
            "splitting decisions: [[2, 72], [2, 72], [2, 72], [2, 72], [2, 72], [2, 72], [2, 72], [2, 72], [2, 72], [2, 72]]\n",
            "best_l after optimization: 0.3068735599517822 with beta sum per layer: [0.0, 0.0, 1.750760555267334]\n",
            "alpha/beta optimization time: 0.22027301788330078\n",
            "This batch time : update_bounds func: 0.2255\t prepare: 0.0025\t bound: 0.2205\t transfer: 0.0013\t finalize: 0.0012\n",
            "Accumulated time: update_bounds func: 1.3891\t prepare: 0.0099\t bound: 1.3725\t transfer: 0.0013\t finalize: 0.0028\n",
            "batch bounding time:  0.22557377815246582\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.07929, 98.506859] (5), [-0.07475, 98.506859] (5), [-0.06821, 98.506859] (5), [-0.06468, 98.506859] (5), [-0.05575, 98.506859] (5), [-0.04803, 98.506859] (5), [-0.04042, 98.506859] (5), [-0.03533, 98.506859] (5), [-0.02158, 98.506859] (5), [-0.01767, 98.506859] (5), [-0.01098, 98.506859] (5), [-0.00694, 98.506859] (5), \n",
            "length of domains: 12\n",
            "Total time: 0.2477\t pickout: 0.0017\t decision: 0.0199\t get_bound: 0.2256\t add_domain: 0.0005\n",
            "Current lb:-0.07928681373596191\n",
            "50 neurons visited\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 3.058124542236328\n",
            "\n",
            "splitting decisions: [[2, 81], [2, 81], [2, 81], [2, 81], [2, 81], [2, 81], [2, 81], [2, 81], [2, 81], [2, 81]]\n",
            "best_l after optimization: -0.34130072593688965 with beta sum per layer: [0.0, 0.0, 0.9448569416999817]\n",
            "alpha/beta optimization time: 0.2122955322265625\n",
            "This batch time : update_bounds func: 0.2174\t prepare: 0.0025\t bound: 0.2125\t transfer: 0.0012\t finalize: 0.0011\n",
            "Accumulated time: update_bounds func: 1.6065\t prepare: 0.0124\t bound: 1.5849\t transfer: 0.0012\t finalize: 0.0039\n",
            "batch bounding time:  0.21748685836791992\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.02676, 98.506859] (6), [-0.02300, 98.506859] (6), [-0.01536, 98.506859] (6), [-0.01431, 98.506859] (6), [-0.01234, 98.506859] (6), [-0.00939, 98.506859] (6), [-0.00372, 98.506859] (6), [-0.00327, 98.506859] (6), \n",
            "length of domains: 8\n",
            "Total time: 0.2385\t pickout: 0.0022\t decision: 0.0185\t get_bound: 0.2175\t add_domain: 0.0003\n",
            "Current lb:-0.026764631271362305\n",
            "74 neurons visited\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 3.2968568801879883\n",
            "\n",
            "splitting decisions: [[2, 64], [2, 64], [2, 64], [2, 64], [2, 64], [2, 64], [2, 64], [2, 64]]\n",
            "\n",
            "all verified at 0th iter\n",
            "best_l after optimization: -0.60596764087677 with beta sum per layer: [0.0, 0.0, 0.7975687980651855]\n",
            "alpha/beta optimization time: 0.007239580154418945\n",
            "This batch time : update_bounds func: 0.0110\t prepare: 0.0020\t bound: 0.0074\t transfer: 0.0008\t finalize: 0.0007\n",
            "Accumulated time: update_bounds func: 1.6174\t prepare: 0.0144\t bound: 1.5923\t transfer: 0.0008\t finalize: 0.0047\n",
            "batch bounding time:  0.010995864868164062\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.0291\t pickout: 0.0014\t decision: 0.0167\t get_bound: 0.0110\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 98.5068588256836, batch ub: inf\n",
            "Cumulative time: 3.326296329498291\n",
            "\n",
            "Image 3 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound 98.5068588256836, time: 3.369304656982422\n",
            "3 1.0000000116860974e-07\n",
            "##### [0:3] Tested against 2 ######\n",
            "Initial alpha-CROWN verified for label 2 with bound 1.4995959997177124\n",
            "Image 3 label 2 verification end, final lower bound 1.4995959997177124, upper bound inf, time: 0.0003447532653808594\n",
            "3 1.4995959997177124\n",
            "##### [0:3] Tested against 1 ######\n",
            "Initial alpha-CROWN verified for label 1 with bound 3.3624868392944336\n",
            "Image 3 label 1 verification end, final lower bound 3.3624868392944336, upper bound inf, time: 0.00033545494079589844\n",
            "3 3.3624868392944336\n",
            "##### [0:3] Tested against 4 ######\n",
            "Initial alpha-CROWN verified for label 4 with bound 4.390303611755371\n",
            "Image 3 label 4 verification end, final lower bound 4.390303611755371, upper bound inf, time: 0.0003371238708496094\n",
            "3 4.390303611755371\n",
            "##### [0:3] Tested against 3 ######\n",
            "Initial alpha-CROWN verified for label 3 with bound 6.79958438873291\n",
            "Image 3 label 3 verification end, final lower bound 6.79958438873291, upper bound inf, time: 0.00034427642822265625\n",
            "3 6.79958438873291\n",
            "##### [0:3] Tested against 6 ######\n",
            "Initial alpha-CROWN verified for label 6 with bound 8.617822647094727\n",
            "Image 3 label 6 verification end, final lower bound 8.617822647094727, upper bound inf, time: 0.0003266334533691406\n",
            "3 8.617822647094727\n",
            "##### [0:3] Tested against 7 ######\n",
            "Initial alpha-CROWN verified for label 7 with bound 8.36134147644043\n",
            "Image 3 label 7 verification end, final lower bound 8.36134147644043, upper bound inf, time: 0.0003304481506347656\n",
            "3 8.36134147644043\n",
            "##### [0:3] Tested against 9 ######\n",
            "Initial alpha-CROWN verified for label 9 with bound 8.567939758300781\n",
            "Image 3 label 9 verification end, final lower bound 8.567939758300781, upper bound inf, time: 0.00034427642822265625\n",
            "3 8.567939758300781\n",
            "##### [0:3] Tested against 5 ######\n",
            "Initial alpha-CROWN verified for label 5 with bound 13.031242370605469\n",
            "Image 3 label 5 verification end, final lower bound 13.031242370605469, upper bound inf, time: 0.00033783912658691406\n",
            "3 13.031242370605469\n",
            "##### [0:3] Tested against 0 ######\n",
            "groundtruth label, skip!\n",
            "Result: image 3 verification success (with branch and bound)!\n",
            "Wall time: 9.885374546051025\n",
            "\n",
            "number of correctly classified examples: 1\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 0): []\n",
            "verification success idx (total 1): [3]\n",
            "verification failure idx (total 0): []\n",
            "final verified acc: 100.0%[1]\n",
            "verifier is called on 1 examples.\n",
            "total verified: 1\n",
            "mean time [cnt:1] (excluding attack success): 8.678000688552856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/170498071 [00:00<?, ?it/s]\r  0%|          | 33792/170498071 [00:00<15:21, 185022.05it/s]\r  0%|          | 132096/170498071 [00:00<05:23, 526297.13it/s]\r  0%|          | 361472/170498071 [00:00<02:22, 1197961.79it/s]\r  1%|          | 885760/170498071 [00:00<01:04, 2621818.58it/s]\r  1%|          | 1819648/170498071 [00:00<00:41, 4101440.88it/s]\r  3%|▎         | 4654080/170498071 [00:00<00:14, 11059507.53it/s]\r  5%|▍         | 8340480/170498071 [00:00<00:08, 18561413.59it/s]\r  7%|▋         | 12010496/170498071 [00:00<00:06, 23883972.90it/s]\r  9%|▉         | 15729664/170498071 [00:01<00:05, 27814789.05it/s]\r 11%|█         | 18957312/170498071 [00:01<00:06, 25163335.84it/s]\r 13%|█▎        | 22410240/170498071 [00:01<00:05, 26561128.07it/s]\r 15%|█▌        | 26354688/170498071 [00:01<00:04, 30022974.14it/s]\r 18%|█▊        | 30077952/170498071 [00:01<00:04, 32022432.85it/s]\r 20%|█▉        | 33383424/170498071 [00:01<00:04, 28627888.68it/s]\r 22%|██▏       | 37029888/170498071 [00:01<00:04, 30698343.31it/s]\r 24%|██▎       | 40387584/170498071 [00:01<00:04, 30792611.98it/s]\r 26%|██▌       | 44057600/170498071 [00:01<00:03, 32378127.76it/s]\r 28%|██▊       | 47547392/170498071 [00:02<00:03, 33044111.32it/s]\r 30%|███       | 51191808/170498071 [00:02<00:03, 34021936.40it/s]\r 32%|███▏      | 54636544/170498071 [00:02<00:03, 30784126.75it/s]\r 34%|███▍      | 58328064/170498071 [00:02<00:03, 32450730.41it/s]\r 36%|███▌      | 61768704/170498071 [00:02<00:03, 32526482.38it/s]\r 38%|███▊      | 65075200/170498071 [00:02<00:03, 32582666.82it/s]\r 40%|████      | 68720640/170498071 [00:02<00:03, 33695015.13it/s]\r 42%|████▏     | 72361984/170498071 [00:02<00:02, 34485658.65it/s]\r 44%|████▍     | 75835392/170498071 [00:02<00:03, 31166640.11it/s]\r 47%|████▋     | 79447040/170498071 [00:03<00:02, 32307573.43it/s]\r 49%|████▊     | 82838528/170498071 [00:03<00:02, 31992324.14it/s]\r 51%|█████     | 86122496/170498071 [00:03<00:02, 32230016.65it/s]\r 53%|█████▎    | 89785344/170498071 [00:03<00:02, 33489878.45it/s]\r 55%|█████▍    | 93461504/170498071 [00:03<00:02, 34439646.02it/s]\r 57%|█████▋    | 96928768/170498071 [00:03<00:02, 34387361.56it/s]\r 59%|█████▉    | 100383744/170498071 [00:03<00:02, 31957654.94it/s]\r 61%|██████    | 103711744/170498071 [00:03<00:02, 32287253.99it/s]\r 63%|██████▎   | 107168768/170498071 [00:03<00:01, 32899459.75it/s]\r 65%|██████▍   | 110484480/170498071 [00:04<00:01, 30917674.53it/s]\r 67%|██████▋   | 114050048/170498071 [00:04<00:01, 32238941.71it/s]\r 69%|██████▉   | 117310464/170498071 [00:04<00:01, 31891653.42it/s]\r 71%|███████   | 120620032/170498071 [00:04<00:01, 32163474.16it/s]\r 73%|███████▎  | 124077056/170498071 [00:04<00:01, 32825218.98it/s]\r 75%|███████▍  | 127375360/170498071 [00:04<00:01, 32769524.49it/s]\r 77%|███████▋  | 131038208/170498071 [00:04<00:01, 33904985.10it/s]\r 79%|███████▉  | 134438912/170498071 [00:04<00:01, 33344325.69it/s]\r 81%|████████  | 137782272/170498071 [00:04<00:00, 33219943.85it/s]\r 83%|████████▎ | 141110272/170498071 [00:04<00:00, 31826834.05it/s]\r 85%|████████▍ | 144406528/170498071 [00:05<00:00, 32152429.48it/s]\r 87%|████████▋ | 147900416/170498071 [00:05<00:00, 32961122.52it/s]\r 89%|████████▊ | 151244800/170498071 [00:05<00:00, 33102604.06it/s]\r 91%|█████████ | 154563584/170498071 [00:05<00:00, 32683451.71it/s]\r 93%|█████████▎| 157838336/170498071 [00:05<00:00, 32693955.05it/s]\r 94%|█████████▍| 161112064/170498071 [00:05<00:00, 32573070.79it/s]\r 97%|█████████▋| 164551680/170498071 [00:05<00:00, 33112891.13it/s]\r 98%|█████████▊| 167866368/170498071 [00:05<00:00, 32462559.77it/s]\r170499072it [00:05, 29212209.59it/s]                               \n",
            "/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tutorial example3: Customization for arbitrary data verification\n",
        "Besides official data loader, one can also easily use α,β-CROWN to verify arbitrarily defined dataset and model. You can even define element-wise perturbation ranges like here."
      ],
      "metadata": {
        "id": "hkBRBpifr5Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a your_model_data.py\n",
        "def two_relu_toy_model(in_dim=2, out_dim=2):\n",
        "    \"\"\"A very simple model, 2 inputs, 2 ReLUs, 2 outputs\"\"\"\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(in_dim, 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(2, out_dim)\n",
        "    )\n",
        "    \"\"\"[relu(x+2y)-relu(2x+y)+2, 0*relu(2x-y)+0*relu(-x+y)]\"\"\"\n",
        "    model[0].weight.data = torch.tensor([[1., 2.], [2., 1.]])\n",
        "    model[0].bias.data = torch.tensor([0., 0.])\n",
        "    model[2].weight.data = torch.tensor([[1., -1.], [0., 0.]])\n",
        "    model[2].bias.data = torch.tensor([2., 0.])\n",
        "    return model\n",
        "\n",
        "def simple_box_data():\n",
        "    \"\"\"a customized box data: x=[-1.5, 1], y=[-1, 1.5]\"\"\"\n",
        "    X = torch.tensor([[0., 0.]]).float()\n",
        "    labels = torch.tensor([0]).long()\n",
        "    # customized element-wise upper bounds\n",
        "    data_max = torch.tensor([[1., 1.5]]).reshape(1, -1)\n",
        "    # customized element-wise lower bounds\n",
        "    data_min = torch.tensor([[-1.5, -1.]]).reshape(1, -1)\n",
        "    eps = None\n",
        "    return X, labels, data_max, data_min, eps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9g5hMe6sWNy",
        "outputId": "67c8f2d1-5862-4f3a-b4c3-5f69313ee800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to your_model_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the config file with customized model \"simple_box\" and dataset \"simple_box_data\""
      ],
      "metadata": {
        "id": "Q2Xvd18-siQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/tutorial_simple_box_example.yaml\n",
        "general:\n",
        "  mode: verified-acc\n",
        "model:\n",
        "  # Use the two_relu_toy_model() model in \"your_model_data.py\".\n",
        "  name: Customized(\"your_model_data\", \"two_relu_toy_model\", in_dim=2, out_dim=2)\n",
        "data:\n",
        "  # Use the simple_box_data() loader in \"your_model_data.py\".\n",
        "  dataset: Customized(\"your_model_data\", \"simple_box_data\")\n",
        "  num_outputs: 2\n",
        "specification:\n",
        "  type: bound\n",
        "attack:\n",
        "  pgd_order: skip\n",
        "solver:\n",
        "  beta-crown:\n",
        "    batch_size: 2048\n",
        "    iteration: 20\n",
        "bab:\n",
        "  timeout: 300\n",
        "  branching:\n",
        "    method: fsb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQYy3OpQsm2L",
        "outputId": "cebcf77a-c3d5-4188-892b-232f7c36c27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing exp_configs/tutorial_simple_box_example.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can just run the verification:"
      ],
      "metadata": {
        "id": "xc84bdrGs-NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate alpha-beta-crown\n",
        "python robustness_verifier.py --config exp_configs/tutorial_simple_box_example.yaml\n",
        "conda deactivate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1v1KQG7s-7O",
        "outputId": "60216bc1-9058-423e-a496-e3f967a5578d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cuda\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: null\n",
            "  name: 'Customized(\"your_model_data\", \"two_relu_toy_model\", in_dim=2, out_dim=2)'\n",
            "data:\n",
            "  start: 0\n",
            "  end: 10000\n",
            "  num_outputs: 2\n",
            "  mean: 0.0\n",
            "  std: 1.0\n",
            "  pkl_path: null\n",
            "  dataset: 'Customized(\"your_model_data\", \"simple_box_data\")'\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: bound\n",
            "  norm: .inf\n",
            "  epsilon: null\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 100\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 2048\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 20\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 200000\n",
            "  decision_thresh: 0\n",
            "  timeout: 300\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: fsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: skip\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 30\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Wed Feb 23 07:37:13 2022 on 19a7eca73961\n",
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=2, out_features=2, bias=True)\n",
            ")\n",
            "Warning: pretrained model path is not given!\n",
            "No epsilon defined!\n",
            "Loaded datasets with per-element lower and upper bounds: max = 1.5, min = -1.5\n",
            "eps set to 1.25. This will not be used for certification, but will be used to determine PGD step size.\n",
            "Task length: 1\n",
            "saving results to Verified_ret_[Customized(\"your_model_data\", \"two_relu_toy_model\", in_dim=2, out_dim=2)]_start=0_end=10000_iter=20_b=2048_timeout=300_branching=fsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 0, correct label 0, image norm 0.0, logits tensor([2., 0.], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Model prediction is: tensor([[2., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[-1.5000]], device='cuda:0') None\n",
            "best_l after optimization: 0.566974401473999 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.6200544834136963\n",
            "initial alpha-CROWN bounds: tensor([[-0.5670]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "##### [0:0] Tested against 1 ######\n",
            "Model prediction is: tensor([[2., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "setting alpha for layer /6 start_node /7\n",
            "0 /5 torch.Size([1, 2])\n",
            "best_l after optimization: 0.5668047666549683 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.4941837787628174\n",
            "alpha-CROWN with fixed intermediate bounds: tensor([[-0.5668]], device='cuda:0', grad_fn=<AsStridedBackward>) None\n",
            "-0.5668047666549683\n",
            "layer 0 size torch.Size([2]) unstable 2\n",
            "-----------------\n",
            "# of unstable neurons: 2\n",
            "-----------------\n",
            "\n",
            "splitting decisions: [[0, 0]]\n",
            "best_l after optimization: 1.1337890625 with beta sum per layer: [0.0]\n",
            "alpha/beta optimization time: 0.2445216178894043\n",
            "This batch time : update_bounds func: 0.2458\t prepare: 0.0007\t bound: 0.2446\t transfer: 0.0002\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 0.2458\t prepare: 0.0007\t bound: 0.2446\t transfer: 0.0002\t finalize: 0.0002\n",
            "batch bounding time:  0.24585318565368652\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "[-0.56680, 98.433105] (1), [-0.56680, 98.433105] (1), \n",
            "length of domains: 2\n",
            "Total time: 0.2468\t pickout: 0.0004\t decision: 0.0005\t get_bound: 0.2459\t add_domain: 0.0001\n",
            "Current lb:-0.5668047666549683\n",
            "2 neurons visited\n",
            "Global ub: 98.43319702148438, batch ub: inf\n",
            "Cumulative time: 0.7467443943023682\n",
            "\n",
            "splitting decisions: [[0, 1], [0, 1]]\n",
            "\n",
            "all verified at 17th iter\n",
            "best_l after optimization: -2.8586277961730957 with beta sum per layer: [0.21749885380268097]\n",
            "alpha/beta optimization time: 0.07190537452697754\n",
            "This batch time : update_bounds func: 0.0732\t prepare: 0.0008\t bound: 0.0720\t transfer: 0.0002\t finalize: 0.0002\n",
            "Accumulated time: update_bounds func: 0.3189\t prepare: 0.0015\t bound: 0.3167\t transfer: 0.0002\t finalize: 0.0003\n",
            "batch bounding time:  0.07323861122131348\n",
            "Current worst splitting domains [lb, ub] (depth):\n",
            "\n",
            "length of domains: 0\n",
            "Total time: 0.0742\t pickout: 0.0003\t decision: 0.0005\t get_bound: 0.0733\t add_domain: 0.0000\n",
            "No domains left, verification finished!\n",
            "Global ub: 98.43319702148438, batch ub: inf\n",
            "Cumulative time: 0.8209695816040039\n",
            "\n",
            "Image 0 label 1 verification end, final lower bound 1.0000000116860974e-07, upper bound 98.43319702148438, time: 0.8358056545257568\n",
            "0 1.0000000116860974e-07\n",
            "##### [0:0] Tested against 0 ######\n",
            "groundtruth label, skip!\n",
            "Result: image 0 verification success (with branch and bound)!\n",
            "Wall time: 1.6869525909423828\n",
            "\n",
            "number of correctly classified examples: 1\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 0): []\n",
            "verification success idx (total 1): [0]\n",
            "verification failure idx (total 0): []\n",
            "final verified acc: 100.0%[1]\n",
            "verifier is called on 1 examples.\n",
            "total verified: 1\n",
            "mean time [cnt:1] (excluding attack success): 1.6623096466064453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dK8s1EFAIG9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}