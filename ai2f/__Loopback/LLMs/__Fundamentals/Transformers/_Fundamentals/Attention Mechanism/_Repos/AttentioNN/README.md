# AttentioNN
All about attention in neural networks described as colab notebooks

## Notebooks

<table class="tg">
  <tr>
    <th class="tg-yw4l"><b>Name</b></th>
    <th class="tg-yw4l"><b>Description</b></th>
    <th class="tg-yw4l"><b>Notebook</b></th>
  </tr>
  <tr>
    <td class="tg-yw4l">Attention maps</td>
    <td class="tg-yw4l">How does a CNN attent to image objects </td>
    <td class="tg-yw4l"><a href="https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/Attention_Maps.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" height = '23px' >
    </a></td>
  </tr>
  <tr>
    <td class="tg-yw4l">Attention in nmt</td>
    <td class="tg-yw4l">Attention mechanism in neural machine translation</td></td>
    <td class="tg-yw4l"><a href="https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/Attention_in_NMT.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" height = '23px' >
    </a></td>
  </tr>
  
  <tr>
    <td class="tg-yw4l">Attention in image captioning</td>
    <td class="tg-yw4l">Attention in image captioning using sof attention and double stochastic regularization</td></td>
    <td class="tg-yw4l"><a href="https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/Attention_in_Image_Captioning.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" height = '23px' >
    </a></td>
  </tr>
  
  <tr>
    <td class="tg-yw4l">Transofrmer I</td>
    <td class="tg-yw4l">Positional encoding, mutli-head attention and point-wise feed-forward neural networks</td></td>
    <td class="tg-yw4l"><a href="https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/TransformerI.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" height = '23px' >
    </a></td>
  </tr>
    <tr>
    <td class="tg-yw4l">Transofrmer II</td>
    <td class="tg-yw4l">Masked multi-head attention with layer normalization</td></td>
    <td class="tg-yw4l"><a href="https://colab.research.google.com/github/zaidalyafeai/AttentioNN/blob/master/TransformerII.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" height = '23px' >
    </a></td>
  </tr>
  
</table>
