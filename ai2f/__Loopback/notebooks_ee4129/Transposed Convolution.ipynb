{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposed Convolution\n",
    "Transposed convolutions also called fractionally strided convolutions or deconvolutions work by swapping the forward and backward passes of a convolution. One way to put it is to note that the kernel defines a convolution, but whether itâ€™s a direct convolution or a transposed convolution is determined by how the forward and backward passes are computed [1]. \n",
    "\n",
    "For instance, although the kernel $\\mathbf{w}$ defines a convolution whose forward and backward passes are computed by multiplying with $\\mathbf{C}$ and $\\mathbf{C}^T$ respectively, it also defines a transposed convolution whose forward and backward passes are computed by multiplying with $\\mathbf{C}^T$ and $(\\mathbf{C}^T)^T = \\mathbf{C}$ respectively.\n",
    "\n",
    "It is defined as SpatialFullConvolution in Torch\n",
    "\n",
    "[1]: Vincent Dumoulin, Francesco Visin - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285 \"A guide to convolution arithmetic for deep learning\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpatialFullConvolution\n",
    "`module = nn.SpatialFullConvolution(nInputPlane, nOutputPlane, kW, kH, [dW], [dH], [padW], [padH], [adjW], [adjH])`\n",
    "\n",
    "Other frameworks call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\", \"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"\n",
    "The parameters are the following:\n",
    "* `nInputPlane:` The number of expected input planes in the image given into `forward()`.\n",
    "* `nOutputPlane:` The number of output planes the convolution layer will produce.\n",
    "* `kW:` The kernel width of the convolution\n",
    "* `kH:` The kernel height of the convolution\n",
    "* `dW:` The step of the convolution in the width dimension. Default is 1.\n",
    "* `dH:` The step of the convolution in the height dimension. Default is 1.\n",
    "* `padW:` Additional zeros added to the input plane data on both sides of width axis. Default is 0. (kW-1)/2 is often used here.\n",
    "* `padH:` Additional zeros added to the input plane data on both sides of height axis. Default is 0. (kH-1)/2 is often used here.\n",
    "* `adjW:` Extra width to add to the output image. Default is 0. Cannot be greater than dW-1.\n",
    "* `adjH:` Extra height to add to the output image. Default is 0. Cannot be greater than dH-1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Normal) Convolution Forward & Backward Pass\n",
    "\n",
    "Layer with kernel size $3 \\times 3$ and stride of $2$, $2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0160  0.4442  0.8234  1.7105  1.9389  1.8970  0.4721  1.4563  0.4023\n",
       "[torch.DoubleTensor of size 1x9]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.SpatialConvolutionMM(1,1,3,3,2,2)\n",
    "conv.weight:uniform(0,2)\n",
    "conv.bias:fill(0)\n",
    "print(conv.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input\n",
    "Image of channel $1$ and size $5 \\times 5$, $r$ is the inputGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgC = torch.Tensor(1,1,5,5)\n",
    "imgC:uniform(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  28.0467  21.1382\n",
       "  23.1202  30.5335\n",
       "[torch.DoubleTensor of size 1x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=conv:forward(imgC)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  28.4956  12.4596  44.5710   9.3905  17.4058\n",
       "  47.9750  54.3784  89.3627  40.9838  40.0994\n",
       "  36.7311  51.1151  71.3240  44.3476  33.6471\n",
       "  39.5481  44.8267  96.0881  59.1999  57.9224\n",
       "  10.9150  33.6697  23.7172  44.4655  12.2851\n",
       "[torch.DoubleTensor of size 1x1x5x5]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv:backward(imgC,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Convolution Forward Pass\n",
    "\n",
    "Layer with kernel size $3 \\times 3$ and stride of $2$, $2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trancon = nn.SpatialFullConvolution(1, 1, 3, 3, 2, 2)\n",
    "trancon.bias:fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  1.0160  0.4442  0.8234\n",
       "  1.7105  1.9389  1.8970\n",
       "  0.4721  1.4563  0.4023\n",
       "[torch.DoubleTensor of size 1x1x3x3]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trancon.weight:copy(conv.weight)\n",
    "trancon.weight:reshape(1,1,3,3)\n",
    "print(trancon.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input\n",
    "Image of channel $1$ and size $2 \\times 2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  28.0467  21.1382\n",
       "  23.1202  30.5335\n",
       "[torch.DoubleTensor of size 1x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass - Note this is exactly same as the backward pass of (normal) convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  28.4956  12.4596  44.5710   9.3905  17.4058\n",
       "  47.9750  54.3784  89.3627  40.9838  40.0994\n",
       "  36.7311  51.1151  71.3240  44.3476  33.6471\n",
       "  39.5481  44.8267  96.0881  59.1999  57.9224\n",
       "  10.9150  33.6697  23.7172  44.4655  12.2851\n",
       "[torch.DoubleTensor of size 1x1x5x5]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trancon:forward(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
