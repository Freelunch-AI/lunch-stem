{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "\r\n",
    "try:\r\n",
    "    sys.path.remove('C:\\\\Python36\\\\Lib\\\\site-packages')\r\n",
    "except:\r\n",
    "    print(\"already unset python36 PYTHONPATH\")\r\n",
    "    pass\r\n",
    "\r\n",
    "#print(sys.path)\r\n",
    "\r\n",
    "import numpy as np # linear algebra\r\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "sns.set()\r\n",
    "\r\n",
    "path = r'C:\\Users\\bruno\\Desktop\\AI\\Artifical Inteligence\\Machine Learning\\Machine Learning (Child)\\ML - _My Hackathons\\Projects\\BigData Hackathon\\Coringas do AndrewNg\\HACKATHON_BIG_DATA'\r\n",
    "path_lojas_atuais = f'{path}/lojas_atuais.csv'\r\n",
    "path_faturamento_lojas_atuais = f'{path}/faturamento_lojas_atuais.csv'\r\n",
    "path_cenarios_expansao = f'{path}/cenarios_expansao.csv'\r\n",
    "\r\n",
    "lojas = pd.read_csv(path_lojas_atuais)\r\n",
    "faturamento = pd.read_csv(path_faturamento_lojas_atuais)\r\n",
    "expansao = pd.read_csv(path_cenarios_expansao)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['c:\\\\Users\\\\bruno\\\\Desktop\\\\kaggle-adult-comp-knn\\\\helpers', '', 'c:\\\\Users\\\\bruno\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.8.2041215044\\\\pythonFiles', 'c:\\\\Users\\\\bruno\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.8.2041215044\\\\pythonFiles\\\\lib\\\\python', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\python38.zip', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\bruno\\\\anaconda3', 'C:\\\\Users\\\\bruno\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib\\\\site-packages\\\\locket-0.2.1-py3.8.egg', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\bruno\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\bruno\\\\.ipython']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Arrumando o dataset para ficar do jeito que vamos treinar "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_ibge = 'tabelas_ibge_uteis/tabela392_csv.csv'\r\n",
    "\r\n",
    "ibge = pd.read_csv(path_ibge, sep=';', encoding='latin1')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#ibge_values = ibge['ï»¿Areas'].values\r\n",
    "#ibge.drop(['ï»¿Areas'], axis=1, inplace=True)\r\n",
    "#ibge['Areas'] = pd.Series(ibge_values)\r\n",
    "ibge.head()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ibge.columns\r\n",
    "ibge = ibge.rename(columns={'Column5': 'renda_media', 'Column11': 'cod_ap'})\r\n",
    "ibge.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ibge = ibge[['cod_ap', 'renda_media']]\r\n",
    "ibge.head()\r\n",
    "ibge.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lojas.sample(30)\r\n",
    "\r\n",
    "# IMPORTANTE -> FEATURES 13 a 15 ou todas estao presentes ou nenhuma esta presente -> tranformar em feature binaria posteriormente"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lojas.isnull().sum()\r\n",
    "print(lojas.dtypes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mudar os types:\r\n",
    "\r\n",
    "# observacao feat 12 e binaria na vdd mas vamos deixar assim, pq\r\n",
    "# ainda teremos que lidar com missing values, entao ter 3 categorias\r\n",
    "# na vdd\r\n",
    "lojas['cod_loja'] = lojas['cod_loja'].astype(str)\r\n",
    "lojas['cod_ap'] = lojas['cod_ap'].astype(str)\r\n",
    "lojas['cod_municipio'] = lojas['cod_municipio'].astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(lojas.shape)\r\n",
    "print(lojas.info())\r\n",
    "print(lojas.duplicated().any())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  lojas onde foi inputado -1 (nao se conhece dados geograficos)\r\n",
    "lojas[lojas['cod_ap'] == '-1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.head(15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(faturamento.shape)\r\n",
    "print(faturamento.info())\r\n",
    "print(faturamento.duplicated().any())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "expansao.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(expansao.shape)\r\n",
    "print(expansao.info())\r\n",
    "print(expansao.duplicated().any())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_loja'].nunique() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(lojas)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(expansao)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.isnull().values.any()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# colocar as categorias para cada mes\r\n",
    "\r\n",
    "cat_concat_list = []\r\n",
    "loja_ano_mes_cont_list = []\r\n",
    "i = 0\r\n",
    "for ((cod_loja, ano, mes), gp) in faturamento.groupby(['cod_loja', 'ano', 'mes']):\r\n",
    "    month_categories = pd.Series(gp['qtde'].values, index=gp['categoria'].values).to_dict()\r\n",
    "    cat_df = pd.DataFrame(month_categories, index=[i])\r\n",
    "    cat_concat_list.append(cat_df)\r\n",
    "    loja_ano_mes_cont_list.append({'cod_loja':cod_loja, 'ano':ano, 'mes':mes})\r\n",
    "    i += 1 \r\n",
    "cat_full = pd.concat([*cat_concat_list])\r\n",
    "loja_ano_mes_cont_full = pd.DataFrame(loja_ano_mes_cont_list)\r\n",
    "loja_ano_mes_cont_full.head(10)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loja_ano_mes_cont_full.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_full.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento = faturamento.groupby(['cod_loja', 'ano', 'mes'])[['qtde', 'receita']].sum().reset_index(drop = True)\r\n",
    "faturamento.shape"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento = pd.concat([loja_ano_mes_cont_full, faturamento, cat_full], axis=1)\r\n",
    "faturamento.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.to_csv('../final/estrabico.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# todas as combinacoes possiveis de loja, ano, mes\r\n",
    "# garantir que nao vai faltar nada\r\n",
    "\r\n",
    "from itertools import product\r\n",
    "\r\n",
    "loja_unique = faturamento['cod_loja'].unique()\r\n",
    "ano_unique = faturamento['ano'].unique()\r\n",
    "mes_unique = faturamento['mes'].unique()\r\n",
    "\r\n",
    "all_combinations = np.vstack(list(product(loja_unique, ano_unique, mes_unique)))\r\n",
    "\r\n",
    "combinations_faturamento = pd.DataFrame(all_combinations, columns=['cod_loja', 'ano', 'mes'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "combinations_faturamento = combinations_faturamento.sort_values(by=['cod_loja', 'ano', 'mes'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento = pd.merge(faturamento, combinations_faturamento, on=['cod_loja', 'ano', 'mes'], how='right')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.loc[faturamento['ano'] == 2016, 'mes_cont'] = faturamento.loc[faturamento['ano'] == 2016, 'mes']\r\n",
    "faturamento.loc[faturamento['ano'] == 2017, 'mes_cont'] = 12 + faturamento.loc[faturamento['ano'] == 2017, 'mes']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(faturamento['CATEG_08'].max())\r\n",
    "print(faturamento['CATEG_08'].mean())\r\n",
    "print(faturamento['CATEG_07'].max())\r\n",
    "print(faturamento['CATEG_07'].mean())\r\n",
    "print(faturamento['CATEG_06'].max())\r\n",
    "print(faturamento['CATEG_06'].mean())\r\n",
    "print(faturamento['CATEG_05'].max())\r\n",
    "print(faturamento['CATEG_05'].mean())\r\n",
    "print(faturamento['CATEG_04'].max())\r\n",
    "print(faturamento['CATEG_04'].mean())\r\n",
    "print(faturamento['CATEG_03'].max())\r\n",
    "print(faturamento['CATEG_03'].mean())\r\n",
    "print(faturamento['CATEG_02'].max())\r\n",
    "print(faturamento['CATEG_02'].mean())\r\n",
    "print(faturamento['CATEG_01'].max())\r\n",
    "print(faturamento['CATEG_01'].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_loja'] = faturamento['cod_loja'].astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento = pd.merge(faturamento, lojas, on='cod_loja', how='inner')\r\n",
    "faturamento.head(12)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_ap'] = faturamento['cod_ap'].astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento = pd.merge(faturamento, ibge, on='cod_ap', how='left')\r\n",
    "faturamento.head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_ap'].nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_municipio'].nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['renda_media'] = faturamento['renda_media'].astype(str).str.translate({32:None, 44:46}).astype(float)\r\n",
    "faturamento['ano'] = faturamento['ano'].astype(str)\r\n",
    "faturamento['mes'] = faturamento['mes'].astype(str)\r\n",
    "faturamento.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# estado\r\n",
    "\r\n",
    "cod_estado = faturamento['cod_municipio'].astype('str').str[:2]\r\n",
    "cod_estado = cod_estado.replace({'11' : 'RO', '12' : 'AC', '13' : 'AM', '14' : 'RR', '15' : 'PA',\r\n",
    "                                 '16' : 'AP', '17' : 'TO', '21' : 'MA', '22' : 'PI', '23' : 'CE',\r\n",
    "                                 '24' : 'RN', '25' : 'PB', '26' : 'PE', '27' : 'AL', '28' : 'SE',\r\n",
    "                                 '29' : 'BA', '31' : 'MG', '32' : 'ES', '33' : 'RJ', '35' : 'SP',\r\n",
    "                                 '41' : 'PR', '42' : 'SC', '43' : 'RS', '50' : 'MS', '51' : 'MT',\r\n",
    "                                 '52' : 'GO', '53' : 'DF'})\r\n",
    "faturamento['estado'] =  cod_estado\r\n",
    "\r\n",
    "# regiao \r\n",
    "\r\n",
    "cod_regiao = faturamento['estado'].astype('str').str[:2]\r\n",
    "cod_regiao = cod_regiao.replace({'RO' : 'NT', 'AC' : 'NT', 'AM' : 'NT', 'RR' : 'NT', 'PA' : 'NT',\r\n",
    "                                 'AP' : 'NT', 'TO' : 'NT', 'MA' : 'NE', 'PI' : 'NE', 'CE' : 'NE',\r\n",
    "                                 'RN' : 'NE', 'PB' : 'NE', 'PE' : 'NE', 'AL' : 'NE', 'SE' : 'NE',\r\n",
    "                                 'BA' : 'NE', 'MG' : 'SD', 'ES' : 'SD', 'RJ' : 'SD', 'PR' : 'SU',\r\n",
    "                                 'SC' : 'SU', 'RS' : 'SU', 'MS' : 'CO', 'MT' : 'CO', 'MS' : 'CO',\r\n",
    "                                 'GO' : 'CO', 'DF' : 'CO'})\r\n",
    "faturamento['regiao'] =  cod_regiao\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.head(15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "localidades = pd.read_csv('localidades.csv', sep=';', encoding='latin1')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "localidades.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "localidades.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "localidades = localidades.rename(columns={'CD_GEOCODSD': 'cod_municipio', 'LONG': 'long', 'LAT': 'lat' })\r\n",
    "localidades = localidades.loc[:, ['cod_municipio', 'long', 'lat']]\r\n",
    "# cod muicipio vem com trailing zeros\r\n",
    "localidades['cod_municipio'] = localidades['cod_municipio'].astype(str).str[:7]\r\n",
    "localidades['lat'] = localidades['lat'].astype(str).str.translate({32:None, 44:46}).astype(float)\r\n",
    "localidades['long'] = localidades['long'].astype(str).str.translate({32:None, 44:46}).astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "localidades.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pegando a media de latitude e longitude das areas como aproximacao do muncipiio\r\n",
    "localidades = localidades.groupby('cod_municipio').mean()\r\n",
    "localidades.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# latitude e longitude por municipio\r\n",
    "faturamento = pd.merge(faturamento, localidades, on='cod_municipio', how='left')\r\n",
    "faturamento.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "percent_missing = faturamento.isnull().sum() * 100 / len(faturamento)\r\n",
    "missing_value_df = pd.DataFrame({'column_name': faturamento.columns,\r\n",
    "                                 'percent_missing': percent_missing}).reset_index(drop=True)\r\n",
    "missing_value_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# observacao importante : tem -1  em cod_ap, cod_municipio, regiao e estado. Por isso que aparece como se nao tivesse nenhum \r\n",
    "# missing value mas na vdd tem. Para substutui os missing values, samplear de uma gaussian fitada nos dados existentes uma boa?\r\n",
    "\r\n",
    "# porem o fato de nao termos os dados diz algo a mais sobre essas lojas? tem relacao com a receita?\r\n",
    "faturamento[faturamento['cod_ap'] == '-1'].sample(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EDA \r\n",
    "    # target variable and aproximate target variable (que a gente nao vai ter para submissao) \r\n",
    "    # pair anlysis\r\n",
    "    # corr matrices\r\n",
    "    # multicolinearity\r\n",
    "    # etc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "    # Obsevacoes:\r\n",
    "        \r\n",
    "        # Check Correlations and Multicolinearity in data\r\n",
    "             # no  test set só teremos cod_loja, mes_cont, cod_ap, cod_municipio, renda_media, lat, long, num_lojas_regiao\r\n",
    "             # sabemos que temos colinearidade forte entre cod_ap e renda_media, e de cod_municipio com lat e long \r\n",
    "             # tambem poderemos ter colinearidade forte de cod_loja com as features da loja\r\n",
    "             # ferramentas: - teste VIF de multicolinearidade; chi-square test for independece, anova, pearson correlation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_loja'].nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(faturamento.info())\r\n",
    "print(faturamento.dtypes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! parei aqui\r\n",
    "# tem 167 lojas que tem meses faltando no ano\r\n",
    "check_months = faturamento.groupby('cod_loja')['mes_cont'].nunique()\r\n",
    "# tem que dar zero\r\n",
    "print(len(check_months[check_months!=24]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento['cod_loja'] = faturamento['cod_loja'].astype(int)\r\n",
    "faturamento['ano'] = faturamento['ano'].astype(int)\r\n",
    "faturamento['mes'] = faturamento['mes'].astype(int)\r\n",
    "faturamento = faturamento.sort_values(by=['cod_loja', 'ano', 'mes'])\r\n",
    "faturamento['cod_loja'] = faturamento['cod_loja'].astype(str)\r\n",
    "faturamento['ano'] = faturamento['ano'].astype(str)\r\n",
    "faturamento['mes'] = faturamento['mes'].astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento[216:240]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# datasets por loja \r\n",
    "# !!! tem lojas com meses faltando !!!\r\n",
    "\r\n",
    "faturamentos_lojas = [ faturamento[24*i:24*i+24] for i in range(3131)]\r\n",
    "\r\n",
    "print(faturamentos_lojas[9]['mes'])\r\n",
    "\r\n",
    "#pegando lojas aleatorias\r\n",
    "for i in range(5):\r\n",
    "    rand = np.random.randint(0, 3131)\r\n",
    "    #plot something\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    dataframe_loja = faturamentos_lojas[rand]\r\n",
    "    #print(dataframe_loja)\r\n",
    "    dataframe_loja['receita'][:12].reset_index(drop=True).plot(kind='line', ax=ax)\r\n",
    "    dataframe_loja['receita'][12:].reset_index(drop=True).plot(kind='line', ax=ax)\r\n",
    "    plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# analise global , media da receita das lojas ao longo do tempo\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "faturamanto_receita_media = faturamento.groupby('mes_cont')['receita'].mean().plot(kind='line', ax=ax)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# diferenca media entre os anos\r\n",
    "faturamanto_receita_media_2016 = faturamanto_receita_media[:13]\r\n",
    "faturamanto_receita_media_2017 = faturamanto_receita_media[13:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Lojas com geo desconhecido (-1) - média geral: {}'.format(faturamento[faturamento['cod_ap'] == '-1']['receita'].mean()))\r\n",
    "print('Lojas com geo desconhecido - std geral: {}'.format(faturamento[faturamento['cod_ap'] == '-1']['receita'].std()))\r\n",
    "print('----------------')\r\n",
    "print('Lojas com geo conhecido - média geral: {}'.format(faturamento[faturamento['cod_ap'] != '-1']['receita'].mean()))\r\n",
    "print('Lojas com geo conhecido - std geral: {}'.format(faturamento[faturamento['cod_ap'] != '-1']['receita'].std()))\r\n",
    "\r\n",
    "# no conjunto de lojas -1 a media eh menor(mas parece bem pouco) e a variancia eh maior (talvez seja reelvante aqui)\r\n",
    "\r\n",
    "# plotar as distribuicoes das receitas\r\n",
    "receitas_geo_desconhecido = faturamento[faturamento['cod_ap'] == '-1']['receita']                                      \r\n",
    "receitas_geo_conhecido = faturamento[faturamento['cod_ap'] != '-1']['receita']\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rows which features from 13 to 18 are NaN\r\n",
    "\r\n",
    "print('Lojas com NaN - média geral: {}'.format(faturamento[faturamento['feature_14'] != faturamento['feature_14']]['receita'].mean()))\r\n",
    "print('Lojas com NaN - std geral: {}'.format(faturamento[faturamento['feature_14'] != faturamento['feature_14']]['receita'].std()))\r\n",
    "print('----------------')\r\n",
    "print('Lojas com features -  média geral:{}'.format(faturamento[faturamento['feature_14'] == faturamento['feature_14']]['receita'].mean()))\r\n",
    "print('Lojas com features -  std geral:{}'.format(faturamento[faturamento['feature_14'] == faturamento['feature_14']]['receita'].std()))\r\n",
    "\r\n",
    "#IMPORTANTE: Lojas que NaN nas features 13-18 tem receita mt menor!\r\n",
    "# lojas quiosque talvez ?\r\n",
    "\r\n",
    "# plotar as dsitribuicoes das receitas\r\n",
    "# ver se as features estao influenciado a receita em faturamento_features_conhecidas (plotar)\r\n",
    "\r\n",
    "receitas_features_NaN = faturamento[faturamento['feature_14'] != faturamento['feature_14']]['receita']\r\n",
    "receitas_features_conhecidas = faturamento[faturamento['feature_14'] == faturamento['feature_14']]['receita']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# influencia do numero de lojas na regiao\r\n",
    "receita_regiao = faturamento.groupby('cod_ap').aggregate({'cod_loja': 'count','receita': 'mean'})\r\n",
    "receita_regiao"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "faturamento.to_csv('../processed/estrabico.csv')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# target-value - receita\r\n",
    "# Tem duas temporadas mesmo de receita? uma no meio do ano e outra no final? \r\n",
    "    #-> daria pra colocar feature binaria pros meses do meio do ano\r\n",
    "# o ano eh importante?\r\n",
    "# testar sazonalidade de trimestre \r\n",
    "# sazonalidade da receita pode ser diferente para cada loja/regiao/categoria?\r\n",
    "#a avliar isso para a media de todas as lojas, media de todas as lojas por regiao\r\n",
    "# "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# lojas grandes e lojas normais? Existem grupos de lojas?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ver o comportamento de tipos de categorias presentes em cada mês "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# como as categorias diferem em vendas e receita, e preço consequentemente?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# como preço da categorias varia durante o tempo?  Inflação importante? "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# agr sobre as features das lojas\r\n",
    "\r\n",
    "# features 7 e 8 bem parecidas?\r\n",
    "# feature 9 parece ter dois grupos definidos, um de valores maiores e outro de valores menores , ver isso aí\r\n",
    "# se features 13-18 sao influentes (pq sempre que elas aparecem, aparecem juntas), e um binario nao eh suficiente:\r\n",
    "    # feature 15 parece ter valores discretos bem definidos, relacionada a fração de alguma coisa, tipo x/10 * 1000 -> substituir por números de 1 a 10? Dividir em grupos maiores?\r\n",
    "    # fature 16 parece ser binária, 500 ou 1000, tratar como binária? ou 1 e 2 ?\r\n",
    "    # features 13, 15, 16 tem os valores máximos = moda = 1000 , colocar features binárias para a presença de max?\r\n",
    "    # feature 4 parece ter 2 grupos de valores: altos e normais. Talvez a questao de lojas grande e normais?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# automatic feature generayion pras features 1-12 (1 - 18 se as features  13-18 forem necessarias)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# clustering (K-means with PCA / t-SNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EDA time series stuff (target variable time-series anlysis)\r\n",
    "# Scipy 2019 tutorial\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Subsitute Missing Values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Treat Outliers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# feature selection and engineering   \r\n",
    "    # - sabemos de antemao a \"cara\" dos resultados no comeco de ano pq a easonalidade é mt forte e a variancia eh pequena para meses\r\n",
    "    # - por isso seria bom dar uma forma dele copiar um pouco o ano passo, serve como uma proxy\r\n",
    "    # - feature categorica que vale: 'Janeiro'; 'Fevereiro', 'Marco', 'Outros'\r\n",
    "    \r\n",
    "    # feature binaria que vale 1 se as features 13 a 18 estao presentes e 0 caso contrario\r\n",
    "    \r\n",
    "    # feature trimestral, comeco do ano, meio, final\r\n",
    "    \r\n",
    "    # feature de numero de lojas na mesmo cod_ap \r\n",
    "    \r\n",
    "    # rotacionar latitude e longitude -> ajuda o modelo de arvore"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Encode Categorical Values\r\n",
    " # mean encodings (pure or rounded)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# build lag_dataset (with lag variables/sliding window)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# build receita_diff (differentiated time series of target value)\r\n",
    "# plot it"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# lembrandoque vamos fazer a previsao do mes seguinte só, depois repetimos o mesmo processo para os proximos meses\r\n",
    "# train-test split \r\n",
    "# test set vai ser os ultimos 3 meses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# local cross validation function\r\n",
    "     # lembrar de fazer sort by loja, pra fazer um stack das predictions [loja1: outubro2017 loja2: outubro2017 ...]\r\n",
    "     # pq na hora de fazer as previsoes vamos empacotar desse jeito"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# global cross validation function (next three months)\r\n",
    "    # prediction\r\n",
    "    # for i in range(1,3):\r\n",
    "    # faturamento_i+1 = append do train_i com prediction_i\r\n",
    "    # fazer tudo denovo\r\n",
    "        # train test split deixando ultimos 3 meses de fora\r\n",
    "        # treinar e cv modelos, treinar e cv ensemble, treinar modelos no dataset inteiro, treinar e cv ensemble no dataset inteiro\r\n",
    "        # conseguir prediction_i \r\n",
    "        # append prediction_i no prediction_months\r\n",
    "    # if cv=True \r\n",
    "        #call local cross validation and return cv \r\n",
    "    # else \r\n",
    "        #return prediction_months"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# baseline model 1\r\n",
    "\r\n",
    "# 0. Separar dataset para cada loja\r\n",
    "# 1. Fazer 2017 - 2016\r\n",
    "# 2. plotar \r\n",
    "# 3. fit and predict with ARIMA (diff = 1)\r\n",
    "# 5. somar valor obtido com 2016\r\n",
    "# 6. juntar as predictions\r\n",
    "# 4. cv ARIMA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# baseline model 2\r\n",
    "\r\n",
    "# 0. Separar dataset para cada loja\r\n",
    "# 1. fit and predict with ARIMA (diff = 1 )\r\n",
    "# 2. somar com valor do mes passado\r\n",
    "# 3  juntar predtions\r\n",
    "# 4. cv ARIMA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# xgboost with lag dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train xgboost with lag dataset parameter tuning"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cv xgboost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train other models\r\n",
    " # remember that with linear models we have to normalize variables"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# other models parameter tuning (if needed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cv other models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ensemble"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cv ensemble"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get parameters of ensemble, train models again on whole dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make predictions wth global cv function (cv=False) for submission"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "66d7c0815ee3ec39f8a25542b36e8def4dce34ad6588e623c666e441b334d01c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}