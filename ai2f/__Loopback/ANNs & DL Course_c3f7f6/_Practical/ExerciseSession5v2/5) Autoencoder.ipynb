{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMox5djGrLZ87lAJHAtPFUX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OrWu1aYZQXjR"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","source":["%cd /gdrive/My Drive/AN2DL/ExerciseSession5v2"],"metadata":{"id":"PfQBBY5hR8ol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install visualkeras\n","import visualkeras"],"metadata":{"id":"bMLSCOYlUkkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","from PIL import Image\n","from sklearn.decomposition import PCA\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"],"metadata":{"id":"c3WKQitiSBu_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"metadata":{"id":"nKVkWxojSDuh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","import logging\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.get_logger().setLevel('INFO')\n","tf.autograph.set_verbosity(0)\n","\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.get_logger().setLevel('ERROR')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"],"metadata":{"id":"thb8rmuGSFVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = tfk.datasets.mnist.load_data()\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=seed, test_size=len(X_test), stratify=y_train)"],"metadata":{"id":"hDHIkW1PSG3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inspect the data\n","num_row = 2\n","num_col = 5\n","fig, axes = plt.subplots(num_row, num_col, figsize=(10*num_row,2*num_col))\n","for i in range(num_row*num_col):\n","    ax = axes[i//num_col, i%num_col]\n","    ax.imshow(np.squeeze(X_train[i]), cmap='gray')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"iy93nXNhSXOG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = (np.expand_dims(X_train, axis=-1)/255.).astype(np.float32)\n","print('Data shape', X_train.shape)\n","print('Data min {:0.2f}\\nData max {:0.2f}\\nData mean {:0.2f}\\nData std {:0.2f}'.format(\n","    X_train.min(), X_train.max(), X_train.mean(), X_train.std()))"],"metadata":{"id":"dkyocr2eSbfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_val = (np.expand_dims(X_val, axis=-1)/255.).astype(np.float32)\n","print('Data shape', X_val.shape)\n","print('Data min {:0.2f}\\nData max {:0.2f}\\nData mean {:0.2f}\\nData std {:0.2f}'.format(\n","    X_val.min(), X_val.max(), X_val.mean(), X_val.std()))"],"metadata":{"id":"KXK-AzPdYwgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = (np.expand_dims(X_test, axis=-1)/255.).astype(np.float32)\n","print('Data shape', X_test.shape)\n","print('Data min {:0.2f}\\nData max {:0.2f}\\nData mean {:0.2f}\\nData std {:0.2f}'.format(\n","    X_test.min(), X_test.max(), X_test.mean(), X_test.std()))"],"metadata":{"id":"ew_phUpwS7UB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_shape = X_train.shape[1:]\n","input_shape"],"metadata":{"id":"X0XEvoRjTCR-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_dim = 2"],"metadata":{"id":"xdOAazigUd0C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Autoencoder"],"metadata":{"id":"dDY30pABTC05"}},{"cell_type":"code","source":["def get_encoder(enc_input_shape=input_shape, enc_output_shape=latent_dim, seed=seed):\n","    tf.random.set_seed(seed)\n","    input_layer = tfkl.Input(shape=enc_input_shape, name='input_layer')\n","    x = tfkl.ZeroPadding2D((2,2))(input_layer)\n","\n","    x = tfkl.Conv2D(64, 3, padding='same', strides=2)(x)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","\n","    x = tfkl.Conv2D(128, 3, padding='same', strides=2)(x)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","\n","    x = tfkl.Conv2D(256, 3, padding='same', strides=2)(x)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","\n","    x = tfkl.Flatten()(x)\n","    output_layer = tfkl.Dense(enc_output_shape, name='output_layer')(x)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='encoder')\n","\n","    # Return the discriminator\n","    return model\n","encoder = get_encoder(input_shape)\n","encoder.summary()\n","display(visualkeras.layered_view(encoder, legend=True, scale_xy=6))\n","tfk.utils.plot_model(encoder, show_shapes=True, expand_nested=True, to_file='encoder.png')"],"metadata":{"id":"z-bhK-JTTFb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_decoder(dec_input_shape=latent_dim, dec_output_shape=input_shape, seed=seed):\n","    tf.random.set_seed(seed)\n","    input_layer = tfkl.Input(shape=dec_input_shape, name='input_layer')\n","    x = tfkl.Dense(4*4*256)(input_layer)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","    x = tfkl.Reshape((4,4,256))(x)\n","\n","    x = tfkl.Conv2DTranspose(128, 3, padding='same', strides=2)(x)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","\n","    x = tfkl.Conv2DTranspose(64, 3, padding='same', strides=2)(x)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","\n","    x = tfkl.Conv2DTranspose(32, 3, padding='same', strides=2)(x)\n","    x = tfkl.BatchNormalization()(x)\n","    x = tfkl.ReLU()(x)\n","\n","    x = tfkl.Conv2D(dec_output_shape[-1], 3, padding='same')(x)\n","    x = tfkl.Activation('sigmoid')(x)\n","    output_layer = tfkl.Cropping2D((2,2))(x)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='decoder')\n","\n","    # Return the discriminator\n","    return model\n","decoder = get_decoder()\n","decoder.summary()\n","display(visualkeras.layered_view(decoder, legend=True, scale_xy=6))\n","tfk.utils.plot_model(decoder, show_shapes=True, expand_nested=True, to_file='decoder.png')"],"metadata":{"id":"Skow1f9xUq5j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_autoencoder(ae_input_shape=input_shape, ae_output_shape=input_shape):\n","    tf.random.set_seed(seed)\n","    \n","    encoder = get_encoder()\n","    decoder = get_decoder()\n","\n","    input_layer = tfkl.Input(shape=ae_input_shape)\n","    z = encoder(input_layer)\n","    output_layer = decoder(z)\n","\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='autoencoder')\n","    return model\n","autoencoder = get_autoencoder()\n","autoencoder.summary()\n","tfk.utils.plot_model(autoencoder, show_shapes=True, expand_nested=True, to_file='autoencoder.png')"],"metadata":{"id":"YMQoFLoOXDAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = 1e-3\n","optimizer = tf.optimizers.Adam(learning_rate)\n","autoencoder.compile(optimizer=optimizer, loss=tfk.losses.binary_crossentropy, metrics=['mse', 'mae'])\n","\n","batch_size = 128\n","epochs = 1000"],"metadata":{"id":"J_POnoUEYLRn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = autoencoder.fit(\n","    X_train,\n","    X_train,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    validation_data=(X_val,X_val),\n","    callbacks=[\n","        tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n","        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-5),\n","    ]\n",").history"],"metadata":{"id":"dxUZzMMjYY5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_epoch = np.argmin(history['val_loss'])\n","plt.figure(figsize=(18,3))\n","plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e', linewidth=3)\n","plt.plot(history['val_loss'], label='Validation', alpha=.9, color='#5a9aa5', linewidth=3)\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.title('Entropy (Loss)')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n","\n","plt.figure(figsize=(18,3))\n","plt.plot(history['mse'], label='Training', alpha=.8, color='#ff7f0e', linewidth=3)\n","plt.plot(history['val_mse'], label='Validation', alpha=.9, color='#5a9aa5', linewidth=3)\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.title('Mean Squared Error')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n","\n","plt.figure(figsize=(18,3))\n","plt.plot(history['mae'], label='Training', alpha=.8, color='#ff7f0e', linewidth=3)\n","plt.plot(history['val_mae'], label='Validation', alpha=.9, color='#5a9aa5', linewidth=3)\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.title('Mean Absolute Error')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n","\n","plt.figure(figsize=(18,3))\n","plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e', linewidth=3)\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()"],"metadata":{"id":"_sqdFKWyZxfg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["autoencoder.save('autoencoder_latent2')"],"metadata":{"id":"PXl2yyu7caNT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["autoencoder_latent2 = tfk.models.load_model('autoencoder_latent2')\n","encoder_latent2 = autoencoder_latent2.get_layer('encoder')\n","decoder_latent2 = autoencoder_latent2.get_layer('decoder')\n","\n","autoencoder_latent16 = tfk.models.load_model('autoencoder_latent16')\n","encoder_latent16 = autoencoder_latent16.get_layer('encoder')\n","decoder_latent2 = autoencoder_latent16.get_layer('decoder')"],"metadata":{"id":"u7_OBiNycbRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_reconstructions(model, X, imgs=10, verbose=True):\n","    predictions = model.predict(X, verbose=0)\n","    fig, axs = plt.subplots(2, imgs, figsize=(imgs*2, 4))\n","    for i in range(imgs):\n","        axs[0, i].imshow(np.squeeze(X[i]), cmap=plt.get_cmap('gray'))\n","        axs.flat[i].axis('off')\n","        axs[1, i].imshow(np.squeeze(predictions[i]), cmap=plt.get_cmap('gray'))\n","        axs.flat[i+imgs].axis('off')\n","    axs[0,imgs//2].set_title('Real data')\n","    axs[1,imgs//2].set_title('Reconstructions')\n","    plt.show()\n","    if verbose:\n","        entropy_score = np.mean(tfk.losses.binary_crossentropy(X, predictions))\n","        mse_score = np.mean(tfk.losses.mean_squared_error(X, predictions))\n","        mae_score = np.mean(tfk.losses.mean_absolute_error(X, predictions))\n","        print('Entropy:',entropy_score)\n","        print('MSE:',mse_score)\n","        print('MAE:',mae_score)\n","\n","get_reconstructions(autoencoder_latent16, X_test)\n","get_reconstructions(autoencoder_latent2, X_test)"],"metadata":{"id":"-hGRt4zAhxmV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Project the training set into the latent space"],"metadata":{"id":"jN4dEvrGc30T"}},{"cell_type":"code","source":["def plot_labels_clusters(encoder, data, labels):\n","    # display a 2D plot of the digit classes in the latent space\n","    z_mean = encoder.predict(data, verbose=0)\n","    if z_mean.shape[-1] != 2:\n","        pca = PCA(n_components=2)\n","        z_mean = pca.fit_transform(z_mean)\n","    plt.figure(figsize=(12, 10))\n","    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n","    plt.colorbar()\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.show()"],"metadata":{"id":"HzQRtotac5IE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_labels_clusters(encoder_latent16, X_train, y_train)\n","plot_labels_clusters(encoder_latent16, X_val, y_val)\n","plot_labels_clusters(encoder_latent16, X_test, y_test)"],"metadata":{"id":"3ARLc9MmiXYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_labels_clusters(encoder_latent2, X_train, y_train)\n","plot_labels_clusters(encoder_latent2, X_val, y_val)\n","plot_labels_clusters(encoder_latent2, X_test, y_test)"],"metadata":{"id":"ixxwqMIeiXby"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Interpolate the latent space and reconstruct"],"metadata":{"id":"AS-mI0WuiMvL"}},{"cell_type":"code","source":["def plot_latent_space(decoder, x_lim, y_lim, n_per_dim=20, digit_size=28, figsize=15):\n","    # display a n*n 2D manifold of digits\n","    figure = np.zeros((digit_size * n_per_dim, digit_size * n_per_dim))\n","    # linearly spaced coordinates corresponding to the 2D plot\n","    # of digit classes in the latent space\n","    grid_x = np.linspace(x_lim[0], x_lim[1], n_per_dim)\n","    grid_y = np.linspace(y_lim[0], y_lim[1], n_per_dim)[::-1]\n","\n","    for i, yi in enumerate(grid_y):\n","        for j, xi in enumerate(grid_x):\n","            # z_sample = np.array([[xi, yi]])\n","            latent = decoder.layers[1].input_shape[-1]\n","            z_sample = np.reshape(np.linspace(xi, yi, latent), (1, latent))\n","            x_decoded = decoder.predict(z_sample, verbose=0)\n","            digit = x_decoded[0].reshape(digit_size, digit_size)\n","            figure[\n","                i * digit_size : (i + 1) * digit_size,\n","                j * digit_size : (j + 1) * digit_size,\n","            ] = digit\n","\n","    plt.figure(figsize=(figsize, figsize))\n","    start_range = digit_size // 2\n","    end_range = n_per_dim * digit_size + start_range\n","    pixel_range = np.arange(start_range, end_range, digit_size)\n","    sample_range_x = np.round(grid_x, 1)\n","    sample_range_y = np.round(grid_y, 1)\n","    plt.xticks(pixel_range, sample_range_x)\n","    plt.yticks(pixel_range, sample_range_y)\n","    plt.xlabel(r'$z_0$', fontsize=24)\n","    plt.ylabel(r'$z_1$', fontsize=24)\n","    plt.xticks(fontsize=18)\n","    plt.yticks(fontsize=18)\n","    plt.title('Latent space - Uniform samples', fontsize=28)\n","    plt.imshow(figure, cmap=\"Greys_r\")\n","    plt.show()"],"metadata":{"id":"KFQJ9V-Hdu7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_latent_space(decoder_latent16, x_lim=(-20,-10), y_lim=(-20,-10))"],"metadata":{"id":"Wi6iUXLJi5Ic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_latent_space(decoder_latent2, x_lim=(0,10), y_lim=(-5,5))"],"metadata":{"id":"9ZvccHlFi5K1"},"execution_count":null,"outputs":[]}]}