As others have pointed out, floating point format is not the same as integer format. Many processors now have hardware floating point and some floating point operations are comparable in speed to integer operations.

integer values all have the same general representation, where the least significant bit is 0 and the most significant bit is 2 raised to (number of bits - 1). For floating point, the bits of the mantissa are scaled by either 2 or 10 raised to the power of (exponent - bias). The processor must extract the mantissa and, depending on the operation, possibly shift the values from both operands to align them for the addition/subtraction. When the result of the operation is produced, it must be converted back into the floating point representation. This all requires several steps more than the equivalent integer operation.