hardware that imporves efficiency of ML workloads: reduces time and/or energy consumption during training and/or inference.