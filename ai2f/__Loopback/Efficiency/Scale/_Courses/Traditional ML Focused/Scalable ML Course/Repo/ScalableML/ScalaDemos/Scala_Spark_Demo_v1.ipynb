{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos from https://github.com/nadimbahadoor/allaboutscala\n",
    "License: Apache 2.0 License - see the LICENSE.TXT file at https://github.com/nadimbahadoor/allaboutscala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 4]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(1 to 100).reduce(_+_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(1 to 100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name = Hello\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Hello"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var name = \"Hello\"\n",
    "println(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   Donut Name|Price|\n",
      "+-------------+-----+\n",
      "|  plain donut|  1.5|\n",
      "|vanilla donut|  2.0|\n",
      "| glazed donut|  2.5|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\n",
       "df = [Donut Name: string, Price: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\n",
    "\n",
    "val df = spark\n",
    "    .createDataFrame(donuts)\n",
    "    .toDF(\"Donut Name\", \"Price\")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donut Name\n",
      "Price\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "columnNames = Array(Donut Name, Price)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name, Price]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columnNames: Array[String] = df.columns\n",
    "  columnNames.foreach(name => println(s\"$name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame column names = Donut Name, Price\n",
      "DataFrame column data types = StringType, DoubleType\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "columnNames = Array(Donut Name, Price)\n",
       "columnDataTypes = Array(StringType, DoubleType)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[StringType, DoubleType]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (columnNames, columnDataTypes) = df.dtypes.unzip\n",
    "println(s\"DataFrame column names = ${columnNames.mkString(\", \")}\")\n",
    "println(s\"DataFrame column data types = ${columnDataTypes.mkString(\", \")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlContext = org.apache.spark.sql.SQLContext@64552914\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@64552914"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlContext.implicits._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagsDF = [stackoverflow: array<struct<tag:struct<author:string,frameworks:array<struct<id:bigint,name:string>>,id:bigint,name:string>>>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stackoverflow: array<struct<tag:struct<author:string,frameworks:array<struct<id:bigint,name:string>>,id:bigint,name:string>>>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tagsDF = spark\n",
    "    .read\n",
    "    .option(\"inferSchema\", true)\n",
    "    .json(\"resources/tags_sample_1line.json\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [stackoverflow_tags: struct<tag: struct<author: string, frameworks: array<struct<id:bigint,name:string>> ... 2 more fields>>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stackoverflow_tags: struct<tag: struct<author: string, frameworks: array<struct<id:bigint,name:string>> ... 2 more fields>>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = tagsDF.select(explode($\"stackoverflow\") as \"stackoverflow_tags\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- stackoverflow_tags: struct (nullable = true)\n",
      " |    |-- tag: struct (nullable = true)\n",
      " |    |    |-- author: string (nullable = true)\n",
      " |    |    |-- frameworks: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      "\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "| id|        author|tag_name|frameworks_id|     frameworks_name|\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "|  1|Martin Odersky|   scala|       [1, 2]|[Play Framework, ...|\n",
      "|  2| James Gosling|    java|       [1, 2]|[Apache Tomcat, S...|\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df.printSchema()\n",
    "\n",
    "  df.select(\n",
    "    $\"stackoverflow_tags.tag.id\" as \"id\",\n",
    "    $\"stackoverflow_tags.tag.author\" as \"author\",\n",
    "    $\"stackoverflow_tags.tag.name\" as \"tag_name\",\n",
    "    $\"stackoverflow_tags.tag.frameworks.id\" as \"frameworks_id\",\n",
    "    $\"stackoverflow_tags.tag.frameworks.name\" as \"frameworks_name\"\n",
    "  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+\n",
      "| Id|   Donut Name|Price|\n",
      "+---+-------------+-----+\n",
      "|111|  plain donut|  1.5|\n",
      "|222|vanilla donut|  2.0|\n",
      "|333| glazed donut|  2.5|\n",
      "+---+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((111,plain donut,1.5), (222,vanilla donut,2.0), (333,glazed donut,2.5))\n",
       "dfDonuts = [Id: string, Donut Name: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Id: string, Donut Name: string ... 1 more field]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"111\",\"plain donut\", 1.50), (\"222\", \"vanilla donut\", 2.0), (\"333\",\"glazed donut\", 2.50))\n",
    "\n",
    "val dfDonuts = spark\n",
    "    .createDataFrame(donuts)\n",
    "    .toDF(\"Id\",\"Donut Name\", \"Price\")\n",
    "\n",
    "dfDonuts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| Id|Inventory|\n",
      "+---+---------+\n",
      "|111|       10|\n",
      "|222|       20|\n",
      "|333|       30|\n",
      "+---+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inventory = List((111,10), (222,20), (333,30))\n",
       "dfInventory = [Id: string, Inventory: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Id: string, Inventory: int]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inventory = Seq((\"111\", 10), (\"222\", 20), (\"333\", 30))\n",
    "val dfInventory = spark\n",
    "      .createDataFrame(inventory)\n",
    "      .toDF(\"Id\", \"Inventory\")\n",
    "\n",
    "dfInventory.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+---------+\n",
      "| Id|   Donut Name|Price|Inventory|\n",
      "+---+-------------+-----+---------+\n",
      "|111|  plain donut|  1.5|       10|\n",
      "|222|vanilla donut|  2.0|       20|\n",
      "|333| glazed donut|  2.5|       30|\n",
      "+---+-------------+-----+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfDonutsInventory = [Id: string, Donut Name: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Id: string, Donut Name: string ... 2 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfDonutsInventory = dfDonuts.join(dfInventory, Seq(\"Id\"), \"inner\")\n",
    "dfDonutsInventory.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------+-------------+--------------------+\n",
      "| id|        author|tag_name|frameworks_id|     frameworks_name|\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "|  1|Martin Odersky|   scala|       [1, 2]|[Play Framework, ...|\n",
      "|  2| James Gosling|    java|       [1, 2]|[Apache Tomcat, S...|\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tagsDF = [stackoverflow: array<struct<tag:struct<author:string,frameworks:array<struct<id:bigint,name:string>>,id:bigint,name:string>>>]\n",
       "df = [id: bigint, author: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: bigint, author: string ... 3 more fields]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tagsDF = spark\n",
    "    .read\n",
    "    .option(\"multiLine\", true)\n",
    "    .option(\"inferSchema\", true)\n",
    "    .json(\"resources/tags_sample_1line.json\")\n",
    "\n",
    "val df = tagsDF\n",
    "    .select(explode($\"stackoverflow\") as \"stackoverflow_tags\")\n",
    "    .select(\n",
    "      $\"stackoverflow_tags.tag.id\" as \"id\",\n",
    "      $\"stackoverflow_tags.tag.author\" as \"author\",\n",
    "      $\"stackoverflow_tags.tag.name\" as \"tag_name\",\n",
    "      $\"stackoverflow_tags.tag.frameworks.id\" as \"frameworks_id\",\n",
    "      $\"stackoverflow_tags.tag.frameworks.name\" as \"frameworks_name\"\n",
    "    )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------+-------------+--------------------+\n",
      "| id|        author|tag_name|frameworks_id|     frameworks_name|\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "|  1|Martin Odersky|   scala|       [1, 2]|[Play Framework, ...|\n",
      "+---+--------------+--------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "  .select(\"*\")\n",
    "  .where(array_contains($\"frameworks_name\",\"Play Framework\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   Donut Name|Price|\n",
      "+-------------+-----+\n",
      "|  plain donut|  1.5|\n",
      "|vanilla donut|  2.0|\n",
      "| glazed donut|  2.5|\n",
      "+-------------+-----+\n",
      "\n",
      "Does price column exist = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\n",
       "df = [Donut Name: string, Price: double]\n",
       "priceColumnExists = true\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\n",
    "val df = spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\")\n",
    "\n",
    "df.show()\n",
    "\n",
    "val priceColumnExists = df.columns.contains(\"Price\")\n",
    "println(s\"Does price column exist = $priceColumnExists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|            Name|    Prices|\n",
      "+----------------+----------+\n",
      "|     Plain Donut|[1.5, 2.0]|\n",
      "|   Vanilla Donut|[2.0, 2.5]|\n",
      "|Strawberry Donut|[2.5, 3.5]|\n",
      "+----------------+----------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Prices: array (nullable = true)\n",
      " |    |-- element: double (containsNull = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "targets = List((Plain Donut,Array(1.5, 2.0)), (Vanilla Donut,Array(2.0, 2.5)), (Strawberry Donut,Array(2.5, 3.5)))\n",
       "df = [Name: string, Prices: array<double>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Name: string, Prices: array<double>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val targets = Seq((\"Plain Donut\", Array(1.50, 2.0)), (\"Vanilla Donut\", Array(2.0, 2.50)), (\"Strawberry Donut\", Array(2.50, 3.50)))\n",
    "\n",
    "val df = spark\n",
    "    .createDataFrame(targets)\n",
    "    .toDF(\"Name\", \"Prices\")\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------+\n",
      "|            Name|Low Price|High Price|\n",
      "+----------------+---------+----------+\n",
      "|     Plain Donut|      1.5|       2.0|\n",
      "|   Vanilla Donut|      2.0|       2.5|\n",
      "|Strawberry Donut|      2.5|       3.5|\n",
      "+----------------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2 = [Name: string, Low Price: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Name: string, Low Price: double ... 1 more field]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df\n",
    "    .select(\n",
    "      $\"Name\",\n",
    "      $\"Prices\"(0).as(\"Low Price\"),\n",
    "      $\"Prices\"(1).as(\"High Price\")\n",
    "    )\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   Donut Name|Price|\n",
      "+-------------+-----+\n",
      "|  plain donut|  1.5|\n",
      "|vanilla donut|  2.0|\n",
      "| glazed donut|  2.5|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\n",
       "df = [Donut Name: string, Price: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\n",
    "\n",
    "val df = spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|            Name|    Prices|\n",
      "+----------------+----------+\n",
      "|     Plain Donut|[1.5, 2.0]|\n",
      "|   Vanilla Donut|[2.0, 2.5]|\n",
      "|Strawberry Donut|[2.5, 3.5]|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2 = [Name: string, Prices: array<double>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Name: string, Prices: array<double>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumnRenamed(\"Donut Name\", \"Name\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+\n",
      "|   Donut Name|Price|Stock Min Max|\n",
      "+-------------+-----+-------------+\n",
      "|  plain donut|  1.5|   [100, 500]|\n",
      "|vanilla donut|  2.0|   [200, 400]|\n",
      "| glazed donut|  2.5|   [300, 600]|\n",
      "+-------------+-----+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\n",
       "df = [Donut Name: string, Price: double]\n",
       "stockMinMax = > Seq[Int] = <function1>\n",
       "udfStockMinMax = UserDefinedFunction(<function1>,ArrayType(IntegerType,false),Some(List(StringType)))\n",
       "df2 = [Donut Name: string, Price: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double ... 1 more field]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\n",
    "val df = spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\")\n",
    "\n",
    "val stockMinMax: (String => Seq[Int]) = (donutName: String) => donutName match {\n",
    "    case \"plain donut\"    => Seq(100, 500)\n",
    "    case \"vanilla donut\"  => Seq(200, 400)\n",
    "    case \"glazed donut\"   => Seq(300, 600)\n",
    "    case _                => Seq(150, 150)\n",
    "}\n",
    "\n",
    "val udfStockMinMax = udf(stockMinMax)\n",
    "val df2 = df.withColumn(\"Stock Min Max\", udfStockMinMax($\"Donut Name\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row = [plain donut,1.5]\n",
      "First row column 1 = plain donut\n",
      "First row column Price = 1.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\n",
       "df = [Donut Name: string, Price: double]\n",
       "firstRow = [plain donut,1.5]\n",
       "firstRowColumn1 = plain donut\n",
       "firstRowColumnPrice = 1.5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\n",
    "  \n",
    "val df = spark\n",
    "    .createDataFrame(donuts)\n",
    "    .toDF(\"Donut Name\", \"Price\")\n",
    "\n",
    "val firstRow = df.first()\n",
    "println(s\"First row = $firstRow\")\n",
    "\n",
    "val firstRowColumn1 = df.first().get(0)\n",
    "println(s\"First row column 1 = $firstRowColumn1\")\n",
    "\n",
    "\n",
    "val firstRowColumnPrice = df.first().getAs[Double](\"Price\")\n",
    "println(s\"First row column Price = $firstRowColumnPrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+---------------+--------------------+--------------+--------------+--------------+---+-----+----+\n",
      "|   Donut Name|Price|Purchase Date|Price Formatted|      Name Formatted|Name Uppercase|Name Lowercase|Date Formatted|Day|Month|Year|\n",
      "+-------------+-----+-------------+---------------+--------------------+--------------+--------------+--------------+---+-----+----+\n",
      "|  plain donut|  1.5|   2018-04-17|           1.50| awesome plain donut|   PLAIN DONUT|   plain donut|      20180417| 17|    4|2018|\n",
      "|vanilla donut|  2.0|   2018-04-01|           2.00|awesome vanilla d...| VANILLA DONUT| vanilla donut|      20180401|  1|    4|2018|\n",
      "| glazed donut|  2.5|   2018-04-02|           2.50|awesome glazed donut|  GLAZED DONUT|  glazed donut|      20180402|  2|    4|2018|\n",
      "+-------------+-----+-------------+---------------+--------------------+--------------+--------------+--------------+---+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5,2018-04-17), (vanilla donut,2.0,2018-04-01), (glazed donut,2.5,2018-04-02))\n",
       "df = [Donut Name: string, Price: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double ... 1 more field]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50, \"2018-04-17\"), (\"vanilla donut\", 2.0, \"2018-04-01\"), (\"glazed donut\", 2.50, \"2018-04-02\"))\n",
    "val df = spark\n",
    "    .createDataFrame(donuts)\n",
    "    .toDF(\"Donut Name\", \"Price\", \"Purchase Date\")\n",
    "\n",
    "\n",
    "df\n",
    "  .withColumn(\"Price Formatted\", format_number($\"Price\", 2))\n",
    "  .withColumn(\"Name Formatted\", format_string(\"awesome %s\", $\"Donut Name\"))\n",
    "  .withColumn(\"Name Uppercase\", upper($\"Donut Name\"))\n",
    "  .withColumn(\"Name Lowercase\", lower($\"Donut Name\"))\n",
    "  .withColumn(\"Date Formatted\", date_format($\"Purchase Date\", \"yyyyMMdd\"))\n",
    "  .withColumn(\"Day\", dayofmonth($\"Purchase Date\"))\n",
    "  .withColumn(\"Month\", month($\"Purchase Date\"))\n",
    "  .withColumn(\"Year\", year($\"Purchase Date\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+----------+--------------------+--------------------+--------------------+\n",
      "|   Donut Name|Price|Purchase Date|      Hash|                 MD5|                SHA1|                SHA2|\n",
      "+-------------+-----+-------------+----------+--------------------+--------------------+--------------------+\n",
      "|  plain donut|  1.5|   2018-04-17|1594998220|53a70d9f08d8bb249...|7882fd7481cb43452...|4aace471ed4433f1b...|\n",
      "|vanilla donut|  2.0|   2018-04-01| 673697474|254c8f04be947ec2c...|5dbbc954723a74fe0...|ccda17c5bc47d1671...|\n",
      "| glazed donut|  2.5|   2018-04-02| 715175419|44199f422534a5736...|aaee30ecdc523fa1e...|6d1568ca8c20ffc0b...|\n",
      "+-------------+-----+-------------+----------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5,2018-04-17), (vanilla donut,2.0,2018-04-01), (glazed donut,2.5,2018-04-02))\n",
       "df = [Donut Name: string, Price: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double ... 1 more field]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50, \"2018-04-17\"), (\"vanilla donut\", 2.0, \"2018-04-01\"), (\"glazed donut\", 2.50, \"2018-04-02\"))\n",
    "val df = spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\", \"Purchase Date\")\n",
    "\n",
    "\n",
    "df\n",
    "  .withColumn(\"Hash\", hash($\"Donut Name\")) // murmur3 hash as default.\n",
    "  .withColumn(\"MD5\", md5($\"Donut Name\"))\n",
    "  .withColumn(\"SHA1\", sha1($\"Donut Name\"))\n",
    "  .withColumn(\"SHA2\", sha2($\"Donut Name\", 256)) // 256 is the number of bits\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+-------------+--------------+------+-------------+-------------+-------------+-------------+---------+------+-------------------+-------------+\n",
      "|   Donut Name|Price|Purchase Date|Contains plain|Length|         Trim|        LTrim|        RTrim|      Reverse|Substring|IsNull|             Concat|      InitCap|\n",
      "+-------------+-----+-------------+--------------+------+-------------+-------------+-------------+-------------+---------+------+-------------------+-------------+\n",
      "|  plain donut|  1.5|   2018-04-17|             7|    11|  plain donut|  plain donut|  plain donut|  tunod nialp|    plain| false|  plain donut - 1.5|  Plain Donut|\n",
      "|vanilla donut|  2.0|   2018-04-01|             9|    13|vanilla donut|vanilla donut|vanilla donut|tunod allinav|    vanil| false|vanilla donut - 2.0|Vanilla Donut|\n",
      "| glazed donut|  2.5|   2018-04-02|             8|    12| glazed donut| glazed donut| glazed donut| tunod dezalg|    glaze| false| glazed donut - 2.5| Glazed Donut|\n",
      "+-------------+-----+-------------+--------------+------+-------------+-------------+-------------+-------------+---------+------+-------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5,2018-04-17), (vanilla donut,2.0,2018-04-01), (glazed donut,2.5,2018-04-02))\n",
       "df = [Donut Name: string, Price: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double ... 1 more field]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50, \"2018-04-17\"), (\"vanilla donut\", 2.0, \"2018-04-01\"), (\"glazed donut\", 2.50, \"2018-04-02\"))\n",
    "  \n",
    "val df = spark\n",
    "    .createDataFrame(donuts)\n",
    "    .toDF(\"Donut Name\", \"Price\", \"Purchase Date\")\n",
    "\n",
    " \n",
    "  \n",
    "df\n",
    "  .withColumn(\"Contains plain\", instr($\"Donut Name\", \"donut\"))\n",
    "  .withColumn(\"Length\", length($\"Donut Name\"))\n",
    "  .withColumn(\"Trim\", trim($\"Donut Name\"))\n",
    "  .withColumn(\"LTrim\", ltrim($\"Donut Name\"))\n",
    "  .withColumn(\"RTrim\", rtrim($\"Donut Name\"))\n",
    "  .withColumn(\"Reverse\", reverse($\"Donut Name\"))\n",
    "  .withColumn(\"Substring\", substring($\"Donut Name\", 0, 5))\n",
    "  .withColumn(\"IsNull\", isnull($\"Donut Name\"))\n",
    "  .withColumn(\"Concat\", concat_ws(\" - \", $\"Donut Name\", $\"Price\"))\n",
    "  .withColumn(\"InitCap\", initcap($\"Donut Name\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|  Donut Name|Price|\n",
      "+------------+-----+\n",
      "| plain donut|  1.5|\n",
      "|        null|  2.0|\n",
      "|glazed donut|  2.5|\n",
      "+------------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|  Donut Name|Price|\n",
      "+------------+-----+\n",
      "| plain donut|  1.5|\n",
      "|glazed donut|  2.5|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "donuts = List((plain donut,1.5), (null,2.0), (glazed donut,2.5))\n",
       "dfWithNull = [Donut Name: string, Price: double]\n",
       "dfWithoutNull = [Donut Name: string, Price: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Donut Name: string, Price: double]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val donuts = Seq((\"plain donut\", 1.50), (null.asInstanceOf[String], 2.0), (\"glazed donut\", 2.50))\n",
    "\n",
    "val dfWithNull = spark\n",
    "    .createDataFrame(donuts)\n",
    "    .toDF(\"Donut Name\", \"Price\")\n",
    "\n",
    "dfWithNull.show()\n",
    "\n",
    "val dfWithoutNull = dfWithNull.na.drop()\n",
    "\n",
    "dfWithoutNull.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
